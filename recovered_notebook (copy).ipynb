{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca2a83b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightglue import LightGlue, SuperPoint, viz2d, DISK, SIFT, ALIKED, DoGHardNet\n",
        "from lightglue.utils import load_image, rbd, match_pair\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd  # Import pandas\n",
        "import glob\n",
        "import math\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "general_folder_path = '/home/oussama/Documents/EPFL/PDS_LUTS/'\n",
        "\n",
        "output_path = general_folder_path + 'panorama.jpg'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Utility function to calculate image corners in homogeneous coordinates\n",
        "def get_homogeneous_corners(width, height):\n",
        "    return np.array([[0, 0, 1], [width, 0, 1], [width, height, 1], [0, height, 1]]).T\n",
        "\n",
        "def warp_perspective_padded1(src, dst, transf):\n",
        "    src_h, src_w = src.shape[:2]\n",
        "    dst_h, dst_w = dst.shape[:2]\n",
        "\n",
        "    # Define the corners of the src image\n",
        "    src_corners = np.array([\n",
        "        [0, 0],\n",
        "        [src_w, 0],\n",
        "        [src_w, src_h],\n",
        "        [0, src_h]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    # Transform the src corners using the homography matrix (transf)\n",
        "    src_corners_transformed = cv2.perspectiveTransform(src_corners[None, :, :], transf)[0]\n",
        "\n",
        "    # Define the corners of the dst image in its own coordinate space\n",
        "    dst_corners = np.array([\n",
        "        [0, 0],\n",
        "        [dst_w, 0],\n",
        "        [dst_w, dst_h],\n",
        "        [0, dst_h]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    # Combine all corners to find the overall bounding box\n",
        "    all_corners = np.vstack((src_corners_transformed, dst_corners))\n",
        "\n",
        "    # Compute the bounding box of all corners\n",
        "    x_min, y_min = np.int32(all_corners.min(axis=0))\n",
        "    x_max, y_max = np.int32(all_corners.max(axis=0))\n",
        "\n",
        "    # Calculate the translation needed to shift images to positive coordinates\n",
        "    shift_x = -x_min\n",
        "    shift_y = -y_min\n",
        "\n",
        "    # Compute the size of the output canvas\n",
        "    output_width = x_max - x_min\n",
        "    output_height = y_max - y_min\n",
        "\n",
        "    # Compute the 3x3 translation matrix to shift the images\n",
        "    translation_matrix = np.array([\n",
        "        [1, 0, shift_x],\n",
        "        [0, 1, shift_y],\n",
        "        [0, 0,      1]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    # Update the transformation matrix to include the translation\n",
        "    new_transf = translation_matrix @ transf\n",
        "\n",
        "    # Warp the src image using the updated transformation matrix\n",
        "    warped = cv2.warpPerspective(src, new_transf, (output_width, output_height))\n",
        "    \n",
        "    # Warp the dst image using only the translation matrix (affine)\n",
        "    dst_pad = cv2.warpAffine(dst, translation_matrix[:2], (output_width, output_height))\n",
        "\n",
        "    # Determine the anchor points\n",
        "    anchorX = int(shift_x)\n",
        "    anchorY = int(shift_y)\n",
        "\n",
        "    # Determine the sign\n",
        "    sign = (anchorX > 0) or (anchorY > 0)\n",
        "\n",
        "    return dst_pad, warped, anchorX, anchorY, sign\n",
        "\n",
        "# Rotate image tensor by specified angle\n",
        "def rotate_image(image, angle):\n",
        "    return TF.rotate(image, angle)\n",
        "\n",
        "def rotate_image1(image, angle):\n",
        "    \"\"\"\n",
        "    Rotate a PyTorch image tensor without cropping and add necessary padding to preserve all content.\n",
        "    Keeps the tensor on its original device (CPU or CUDA).\n",
        "    Args:\n",
        "        image: A PyTorch tensor in CHW format with values in [0, 1].\n",
        "        angle: Rotation angle in degrees (counterclockwise).\n",
        "    Returns:\n",
        "        Rotated image as a PyTorch tensor on the same device.\n",
        "    \"\"\"\n",
        "    device = image.device  # Store original device (CPU or CUDA)\n",
        "\n",
        "    # Convert tensor to NumPy array (HWC format)\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image_np = image.permute(1, 2, 0).cpu().numpy()  # CHW -> HWC on CPU\n",
        "        if image_np.max() <= 1:  # Scale up to [0, 255] if needed\n",
        "            image_np = (image_np * 255).astype(np.uint8)\n",
        "    else:\n",
        "        raise TypeError(\"Input must be a PyTorch tensor in CHW format.\")\n",
        "\n",
        "    # Get the height and width of the image\n",
        "    h, w = image_np.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "\n",
        "    # Compute the rotation matrix and new dimensions\n",
        "    rotation_matrix = cv.getRotationMatrix2D(center, angle, 1.0)\n",
        "    cos_val = abs(rotation_matrix[0, 0])\n",
        "    sin_val = abs(rotation_matrix[0, 1])\n",
        "    new_w = int((h * sin_val) + (w * cos_val))\n",
        "    new_h = int((h * cos_val) + (w * sin_val))\n",
        "\n",
        "    # Adjust the rotation matrix to account for translation\n",
        "    rotation_matrix[0, 2] += (new_w / 2) - center[0]\n",
        "    rotation_matrix[1, 2] += (new_h / 2) - center[1]\n",
        "\n",
        "    # Perform rotation with padding\n",
        "    rotated_image_np = cv.warpAffine(\n",
        "        image_np, rotation_matrix, (new_w, new_h),\n",
        "        flags=cv.INTER_CUBIC,\n",
        "        borderMode=cv.BORDER_CONSTANT,\n",
        "        borderValue=(0, 0, 0)\n",
        "    )\n",
        "\n",
        "    # Convert back to PyTorch tensor (CHW format)\n",
        "    rotated_image_tensor = torch.from_numpy(rotated_image_np).permute(2, 0, 1).float()\n",
        "    if rotated_image_tensor.max() > 1:  # Normalize back to [0, 1]\n",
        "        rotated_image_tensor /= 255.0\n",
        "\n",
        "    # Move the tensor back to the original device\n",
        "    return rotated_image_tensor.to(device)\n",
        "\n",
        "# Calculate similarity score between two images\n",
        "def compute_similarity_score(image1, image2, extractor, matcher):\n",
        "    with torch.no_grad():\n",
        "        feats0 = extractor.extract(image1)\n",
        "        feats1 = extractor.extract(image2)\n",
        "        feats0, feats1, matches01 = match_pair(extractor, matcher, image1, image2)\n",
        "    points0 = feats0['keypoints'][matches01['matches'][..., 0]]\n",
        "    score = points0.shape[0]\n",
        "    # Release GPU memory\n",
        "    del feats0, feats1, matches01, points0\n",
        "    torch.cuda.empty_cache()\n",
        "    return score\n",
        "\n",
        "def split_image_paths(image_paths):\n",
        "    \"\"\"\n",
        "    Splits the image_paths list into two halves:\n",
        "    - First half gets an extra frame if the total number of images is odd.\n",
        "    - Second half is reversed to start from the last image and go to the middle.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of image paths.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (first_half, second_half) - two lists of image paths.\n",
        "    \"\"\"\n",
        "    # Compute the midpoint\n",
        "    mid = (len(image_paths) + 1) // 2\n",
        "\n",
        "    # Split the list\n",
        "    first_half = image_paths[:mid]  # First half\n",
        "    second_half = image_paths[mid:][::-1]  # Second half, reversed\n",
        "\n",
        "    return first_half, second_half\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd67f660",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature extractor and matcher initialization\n",
        "extractor = DoGHardNet(max_num_keypoints=None).eval().cuda()\n",
        "matcher = LightGlue(features='doghardnet').eval().cuda()\n",
        "\n",
        "start = True\n",
        "general_folder_path = '/home/oussama/Documents/EPFL/PDS_LUTS/'\n",
        "image_folder = os.path.join(general_folder_path, 'images_updated')\n",
        "\n",
        "indice = 0\n",
        "\n",
        "# Get all .jpg files in the folder\n",
        "image_paths = glob.glob(os.path.join(image_folder, '*.jpg'))\n",
        "# Optionally, sort the image paths if order matters\n",
        "image_paths.sort()\n",
        "\n",
        "image_paths = image_paths[indice:] + image_paths[:indice]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "394e0abc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load images\n",
        "image_path0  = image_paths[0]\n",
        "\n",
        "# Save first image\n",
        "cv.imwrite(general_folder_path+'warped_image.jpg', cv.imread(image_path0))\n",
        "\n",
        "image0 = load_image(image_path0)\n",
        "\n",
        "# Initialize DataFrame for image corners\n",
        "image_corners_df = pd.DataFrame(columns=['image_path', 'corners', 'frame_number'])\n",
        "\n",
        "# Add first image's corners to the DataFrame\n",
        "first_image_corners = np.array([[0, 0], [image0.shape[2]-1, 0],\n",
        "                                [image0.shape[2]-1, image0.shape[1]-1],\n",
        "                                [0, image0.shape[1]-1]], dtype=np.int32)\n",
        "\n",
        "frame_number = os.path.splitext(os.path.basename(image_path0))[0]\n",
        "\n",
        "new_row = pd.DataFrame({\n",
        "    'image_path': [image_path0],\n",
        "    'corners': [first_image_corners],\n",
        "    'frame_number': [frame_number]\n",
        "})\n",
        "\n",
        "image_corners_df = pd.concat([image_corners_df, new_row], ignore_index=True)\n",
        "first_half, second_half = split_image_paths(image_paths)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42fe32b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "num = 0\n",
        "best = 0\n",
        "\n",
        "for idx in tqdm(range(indice + 1, len(first_half))):\n",
        "    # image_path0 = general_folder_path + 'anchor_test.jpg'\n",
        "    if not start:\n",
        "        image_path0  = general_folder_path + 'warped_image.jpg'\n",
        "\n",
        "    image0 = load_image(image_path0)\n",
        "\n",
        "    image_path1  = first_half[idx]\n",
        "\n",
        "    image1 = load_image(image_path1)\n",
        "\n",
        "    # Determine best rotation angle\n",
        "    rotation_angles = range(0, 360, 45)\n",
        "    best_score, best_angle = -1, 0\n",
        "\n",
        "    for angle in rotation_angles:\n",
        "        rotated_image1 = rotate_image(image1, angle)\n",
        "        score = compute_similarity_score(image0, rotated_image1, extractor, matcher)\n",
        "        if score > best_score:\n",
        "            best_score, best_angle = score, angle\n",
        "    best_rotated_image = rotate_image(image1, best_angle)\n",
        "    # Prepare images for final stitching\n",
        "    imocv0 = cv.imread(image_path0)\n",
        "    imocv1 = cv.cvtColor(np.array(TF.to_pil_image(best_rotated_image.cpu()).convert(\"RGB\")), cv.COLOR_RGB2BGR)\n",
        "    cv.imwrite(general_folder_path + 'rotated_image.jpg', imocv1)\n",
        "\n",
        "    # Extract keypoints and compute homography matrix\n",
        "    feats0, feats1, matches01 = match_pair(extractor, matcher, image0, best_rotated_image)\n",
        "    points0 = feats0['keypoints'][matches01['matches'][..., 0]].cpu().numpy()\n",
        "    points1 = feats1['keypoints'][matches01['matches'][..., 1]].cpu().numpy()\n",
        "\n",
        "    if points0.shape[0] >= 4:\n",
        "        M, _ = cv.findHomography(points1, points0, cv.RANSAC, 5.0)\n",
        "        \n",
        "        if num % 1 == 0:\n",
        "            M_normalized = M / M[2, 2]\n",
        "\n",
        "            # Extract the rotation and translation components\n",
        "            M = np.array([\n",
        "                [M_normalized[0, 0], M_normalized[0, 1], M_normalized[0, 2]],\n",
        "                [M_normalized[1, 0], M_normalized[1, 1], M_normalized[1, 2]],\n",
        "                [M_normalized[2, 0],                 0,                 1]\n",
        "            ])\n",
        "        num += 1\n",
        "        # angle_rad = math.atan2(M_normalized[1, 0], M_normalized[0, 0])  # Returns the angle in radians\n",
        "        angle_rad = math.atan2(M[1, 0], M[0, 0])  # Returns the angle in radians\n",
        "        angle_deg = math.degrees(angle_rad) - best_angle\n",
        "        dst_padded, warped_image, anchorX1, anchorY1, sign = warp_perspective_padded1(imocv1, imocv0, M)\n",
        "\n",
        "        before_last_key = image_corners_df['image_path'].iloc[-1]\n",
        "        warped_image_corners = image_corners_df.loc[image_corners_df['image_path'] == before_last_key, 'corners'].values[0]\n",
        "        x_coords, y_coords = warped_image_corners[:, 0], warped_image_corners[:, 1]\n",
        "\n",
        "        # Define source corners as a numpy array of four points\n",
        "        corners = np.array([[x_coords[0], y_coords[0]],\n",
        "                            [x_coords[1], y_coords[1]],\n",
        "                            [x_coords[2], y_coords[2]],\n",
        "                            [x_coords[3], y_coords[3]]], dtype=np.float32)\n",
        "\n",
        "        b_x_min, b_y_min = np.min(corners, axis=0).astype(int)\n",
        "        b_x_max, b_y_max = np.max(corners, axis=0).astype(int)\n",
        "\n",
        "        # Define source corners as a numpy array and convert to float32\n",
        "        new_image_corners = np.array([[0, 0], [imocv1.shape[1], 0],\n",
        "                                    [imocv1.shape[1], imocv1.shape[0]],\n",
        "                                    [0, imocv1.shape[0]]], dtype=np.float32)\n",
        "\n",
        "        # Perform perspective transform with correctly typed data\n",
        "        transformed_corners = cv.perspectiveTransform(np.array([new_image_corners], dtype=np.float32), M)[0]\n",
        "\n",
        "        # Update image_corners_df\n",
        "        # adjusted_corners = transformed_corners + [b_x_min, b_y_min]\n",
        "        adjusted_corners = transformed_corners + [anchorX1, anchorY1]\n",
        "        new_row = pd.DataFrame({\n",
        "            'image_path': [image_path1],\n",
        "            'corners': [adjusted_corners],\n",
        "            'frame_number': [os.path.splitext(os.path.basename(image_path1))[0]]\n",
        "        })\n",
        "        image_corners_df = pd.concat([image_corners_df, new_row], ignore_index=True)\n",
        "\n",
        "        if start:\n",
        "            idx0 = image_corners_df[image_corners_df['image_path'] == image_path0].index[0]\n",
        "            image_corners_df.at[idx0, 'corners'] += [anchorX1, anchorY1]\n",
        "            (anchorX, anchorY) = (0, 0)\n",
        "\n",
        "        # Overlay warped image onto padded destination\n",
        "        non_zero_mask = (warped_image > 0).astype(np.uint8)\n",
        "        dst_padded[non_zero_mask == 1] = warped_image[non_zero_mask == 1]\n",
        "\n",
        "        # Get last and before last keys\n",
        "        last_key = image_corners_df['image_path'].iloc[-1]\n",
        "        warped_image_corners = image_corners_df.loc[image_corners_df['image_path'] == last_key, 'corners'].values[0]\n",
        "        x_coords, y_coords = warped_image_corners[:, 0], warped_image_corners[:, 1]\n",
        "\n",
        "        # Define source corners as a numpy array of four points\n",
        "        corners = np.array([[x_coords[0], y_coords[0]],\n",
        "                            [x_coords[1], y_coords[1]],\n",
        "                            [x_coords[2], y_coords[2]],\n",
        "                            [x_coords[3], y_coords[3]]], dtype=np.float32)\n",
        "\n",
        "        x_min, y_min = np.min(corners, axis=0).astype(int)\n",
        "        x_max, y_max = np.max(corners, axis=0).astype(int)\n",
        "\n",
        "        image_corners_0 = image_corners_df.loc[image_corners_df['image_path'] == before_last_key, 'corners'].values[0]\n",
        "        image_corners_1 = image_corners_df.loc[image_corners_df['image_path'] == last_key, 'corners'].values[0]\n",
        "\n",
        "        # Crop the region of interest\n",
        "        warped_image = warped_image[y_min:y_max, x_min:x_max]\n",
        "        cv.imwrite(general_folder_path + 'warped_image.jpg', warped_image)\n",
        "\n",
        "        # # Crop the region of interest\n",
        "        # image2 = load_image(first_half[idx])\n",
        "        # image2 = rotate_image(image2, -angle_deg)\n",
        "        # warped_image = image2\n",
        "        # cv.imwrite(general_folder_path+'warped_image.jpg', cv.cvtColor(np.array(TF.to_pil_image(image2.cpu()).convert(\"RGB\")), cv.COLOR_RGB2BGR))\n",
        "\n",
        "        # Save final images\n",
        "        cv.imwrite(general_folder_path + 'panorama.jpg', dst_padded)\n",
        "    else:\n",
        "        print(\"Not enough points to compute homography.\")\n",
        "\n",
        "    if start:\n",
        "        cv.imwrite(general_folder_path+'aligned_image.jpg', cv.imread(general_folder_path+'panorama.jpg'))\n",
        "\n",
        "    # Load the images\n",
        "    current_panorama = cv.imread(general_folder_path + 'panorama.jpg')\n",
        "    new_image = cv.imread(general_folder_path + 'aligned_image.jpg')\n",
        "\n",
        "    # Create a 3x3 translation matrix\n",
        "    translation_matrix = np.float32([\n",
        "        [1, 0, b_x_min - anchorX1],\n",
        "        [0, 1, b_y_min - anchorY1],\n",
        "        [0, 0, 1]\n",
        "    ])\n",
        "\n",
        "    if start:\n",
        "        # Create a 3x3 translation matrix Identity matrix\n",
        "        translation_matrix = np.float32([\n",
        "            [1, 0, 0],\n",
        "            [0, 1, 0],\n",
        "            [0, 0, 1]\n",
        "        ])\n",
        "\n",
        "    # Apply the translation to the images\n",
        "    dst_padded, warped_image, anchorX, anchorY, _ = warp_perspective_padded1(current_panorama, new_image, translation_matrix)\n",
        "    idx = image_corners_df[image_corners_df['image_path'] == last_key].index[0]\n",
        "    if not start:\n",
        "        image_corners_df.at[idx, 'corners'] += [b_x_min - anchorX1 + anchorX, b_y_min -anchorY1 + anchorY]\n",
        "    for img_path in image_corners_df['image_path']:\n",
        "        if img_path != image_path1:\n",
        "            idx = image_corners_df[image_corners_df['image_path'] == img_path].index[0]\n",
        "            image_corners_df.at[idx, 'corners'] += [anchorX, anchorY]\n",
        "    start = False\n",
        "    # # Update image_corners for image_path1\n",
        "    # idx1 = image_corners_df[image_corners_df['image_path'] == image_path1].index[0]\n",
        "    # image_corners_df.at[idx1, 'corners'] = transformed_corners + [anchorX, anchorY]\n",
        "    # image_corners_df.at[idx1, 'corners'] = image_corners_df.at[idx1, 'corners'].astype(np.int32)\n",
        "\n",
        "    # Create a mask where dst_padded has zero pixels\n",
        "    mask_dst = cv.cvtColor(dst_padded, cv.COLOR_BGR2GRAY)\n",
        "    mask_dst = (mask_dst == 0).astype(np.uint8)\n",
        "\n",
        "    # Ensure mask has three channels\n",
        "    mask_dst_3ch = cv.merge([mask_dst, mask_dst, mask_dst])\n",
        "\n",
        "    # Combine images by filling zeros in dst_padded with pixels from warped_image\n",
        "    combined_image = dst_padded.copy()\n",
        "    combined_image[mask_dst_3ch == 1] = warped_image[mask_dst_3ch == 1]\n",
        "\n",
        "    # Save the combined image\n",
        "    cv.imwrite(general_folder_path + 'aligned_image.jpg', combined_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5116344d",
      "metadata": {},
      "outputs": [],
      "source": [
        "indice = 0\n",
        "\n",
        "start = True\n",
        "\n",
        "num = 0\n",
        "\n",
        "for idx in tqdm(range(indice + 1, len(second_half))):\n",
        "    # image_path0 = general_folder_path + 'anchor_test.jpg'\n",
        "    if not start:\n",
        "        image_path0  = general_folder_path + 'warped_image.jpg'\n",
        "    else:\n",
        "        image_path0  = image_paths[0]\n",
        "\n",
        "    image0 = load_image(image_path0)\n",
        "\n",
        "    image_path1  = second_half[idx]\n",
        "\n",
        "    image1 = load_image(image_path1)\n",
        "\n",
        "    # Determine best rotation angle\n",
        "    rotation_angles = range(0, 360, 45)\n",
        "    best_score, best_angle = -1, 0\n",
        "\n",
        "    for angle in rotation_angles:\n",
        "        rotated_image1 = rotate_image(image1, angle)\n",
        "        score = compute_similarity_score(image0, rotated_image1, extractor, matcher)\n",
        "        if score > best_score:\n",
        "            best_score, best_angle = score, angle\n",
        "            best_rotated_image = rotated_image1\n",
        "\n",
        "    # Prepare images for final stitching\n",
        "    imocv0 = cv.imread(image_path0)\n",
        "    imocv1 = cv.cvtColor(np.array(TF.to_pil_image(best_rotated_image.cpu()).convert(\"RGB\")), cv.COLOR_RGB2BGR)\n",
        "\n",
        "    # Extract keypoints and compute homography matrix\n",
        "    feats0, feats1, matches01 = match_pair(extractor, matcher, image0, best_rotated_image)\n",
        "    points0 = feats0['keypoints'][matches01['matches'][..., 0]].cpu().numpy()\n",
        "    points1 = feats1['keypoints'][matches01['matches'][..., 1]].cpu().numpy()\n",
        "\n",
        "    if points0.shape[0] >= 4:\n",
        "        M, _ = cv.findHomography(points1, points0, cv.RANSAC, 5.0)\n",
        "        \n",
        "        if num % 1 == 0:\n",
        "            M_normalized = M / M[2, 2]\n",
        "\n",
        "            # Extract the rotation and translation components\n",
        "            M = np.array([\n",
        "                [M_normalized[0, 0], M_normalized[0, 1], M_normalized[0, 2]],\n",
        "                [M_normalized[1, 0], M_normalized[1, 1], M_normalized[1, 2]],\n",
        "                [M_normalized[2, 0],                 0,                 1]\n",
        "            ])\n",
        "        num += 1\n",
        "        # angle_rad = math.atan2(M_normalized[1, 0], M_normalized[0, 0])  # Returns the angle in radians\n",
        "        angle_rad = math.atan2(M[1, 0], M[0, 0])  # Returns the angle in radians\n",
        "        angle_deg = math.degrees(angle_rad) + best_angle\n",
        "\n",
        "        dst_padded, warped_image, anchorX1, anchorY1, sign = warp_perspective_padded1(imocv1, imocv0, M)\n",
        "\n",
        "        if start:\n",
        "            before_last_key = image_corners_df['image_path'].iloc[0]\n",
        "            warped_image_corners = image_corners_df.loc[image_corners_df['image_path'] == before_last_key, 'corners'].values[0]\n",
        "            x_coords, y_coords = warped_image_corners[:, 0], warped_image_corners[:, 1]\n",
        "        else : \n",
        "            before_last_key = image_corners_df['image_path'].iloc[-1]\n",
        "            warped_image_corners = image_corners_df.loc[image_corners_df['image_path'] == before_last_key, 'corners'].values[0]\n",
        "            x_coords, y_coords = warped_image_corners[:, 0], warped_image_corners[:, 1]\n",
        "\n",
        "        # Define source corners as a numpy array of four points\n",
        "        corners = np.array([[x_coords[0], y_coords[0]],\n",
        "                            [x_coords[1], y_coords[1]],\n",
        "                            [x_coords[2], y_coords[2]],\n",
        "                            [x_coords[3], y_coords[3]]], dtype=np.float32)\n",
        "\n",
        "        b_x_min, b_y_min = np.min(corners, axis=0).astype(int)\n",
        "        b_x_max, b_y_max = np.max(corners, axis=0).astype(int)\n",
        "\n",
        "        # Define source corners as a numpy array and convert to float32\n",
        "        new_image_corners = np.array([[0, 0], [imocv1.shape[1], 0],\n",
        "                                    [imocv1.shape[1], imocv1.shape[0]],\n",
        "                                    [0, imocv1.shape[0]]], dtype=np.float32)\n",
        "\n",
        "        # Perform perspective transform with correctly typed data\n",
        "        transformed_corners = cv.perspectiveTransform(np.array([new_image_corners], dtype=np.float32), M)[0]\n",
        "\n",
        "        # Update image_corners_df\n",
        "        # adjusted_corners = transformed_corners + [b_x_min, b_y_min]\n",
        "        adjusted_corners = transformed_corners + [anchorX1, anchorY1]\n",
        "        new_row = pd.DataFrame({\n",
        "            'image_path': [image_path1],\n",
        "            'corners': [adjusted_corners],\n",
        "            'frame_number': [os.path.splitext(os.path.basename(image_path1))[0]]\n",
        "        })\n",
        "        image_corners_df = pd.concat([image_corners_df, new_row], ignore_index=True)\n",
        "        \n",
        "        # Overlay warped image onto padded destination\n",
        "        non_zero_mask = (warped_image > 0).astype(np.uint8)\n",
        "        dst_padded[non_zero_mask == 1] = warped_image[non_zero_mask == 1]\n",
        "\n",
        "        # Get last and before last keys\n",
        "        last_key = image_corners_df['image_path'].iloc[-1]\n",
        "        warped_image_corners = image_corners_df.loc[image_corners_df['image_path'] == last_key, 'corners'].values[0]\n",
        "        x_coords, y_coords = warped_image_corners[:, 0], warped_image_corners[:, 1]\n",
        "\n",
        "        # Define source corners as a numpy array of four points\n",
        "        corners = np.array([[x_coords[0], y_coords[0]],\n",
        "                            [x_coords[1], y_coords[1]],\n",
        "                            [x_coords[2], y_coords[2]],\n",
        "                            [x_coords[3], y_coords[3]]], dtype=np.float32)\n",
        "\n",
        "        x_min, y_min = np.min(corners, axis=0).astype(int)\n",
        "        x_max, y_max = np.max(corners, axis=0).astype(int)\n",
        "\n",
        "        image_corners_0 = image_corners_df.loc[image_corners_df['image_path'] == before_last_key, 'corners'].values[0]\n",
        "        image_corners_1 = image_corners_df.loc[image_corners_df['image_path'] == last_key, 'corners'].values[0]\n",
        "\n",
        "        # Crop the region of interest\n",
        "        warped_image = warped_image[y_min:y_max, x_min:x_max]\n",
        "        cv.imwrite(general_folder_path + 'warped_image.jpg', warped_image)\n",
        "\n",
        "        # image2 = load_image(second_half[idx])\n",
        "        # image2 = rotate_image1(image2, -angle_deg)\n",
        "        # warped_image = image2\n",
        "        # cv.imwrite(general_folder_path+'warped_image.jpg', cv.cvtColor(np.array(TF.to_pil_image(image2.cpu()).convert(\"RGB\")), cv.COLOR_RGB2BGR))\n",
        "\n",
        "        # Save final images\n",
        "        cv.imwrite(general_folder_path + 'panorama.jpg', dst_padded)\n",
        "    else:\n",
        "        print(\"Not enough points to compute homography.\")\n",
        "\n",
        "    # Load the images\n",
        "    current_panorama = cv.imread(general_folder_path + 'panorama.jpg')\n",
        "    new_image = cv.imread(general_folder_path + 'aligned_image.jpg')\n",
        "\n",
        "    # Create a 3x3 translation matrix\n",
        "    translation_matrix = np.float32([\n",
        "        [1, 0, b_x_min - anchorX1],\n",
        "        [0, 1, b_y_min - anchorY1],\n",
        "        [0, 0, 1]\n",
        "    ])\n",
        "\n",
        "    # Apply the translation to the images\n",
        "    dst_padded, warped_image, anchorX, anchorY, _ = warp_perspective_padded1(current_panorama, new_image, translation_matrix)\n",
        "    idx = image_corners_df[image_corners_df['image_path'] == last_key].index[0]\n",
        "    image_corners_df.at[idx, 'corners'] += [b_x_min - anchorX1 + anchorX, b_y_min -anchorY1 + anchorY]\n",
        "    for img_path in image_corners_df['image_path']:\n",
        "        if img_path != image_path1:\n",
        "            idx = image_corners_df[image_corners_df['image_path'] == img_path].index[0]\n",
        "            image_corners_df.at[idx, 'corners'] += [anchorX, anchorY]\n",
        "\n",
        "    start = False\n",
        "\n",
        "    # Create a mask where dst_padded has zero pixels\n",
        "    mask_dst = cv.cvtColor(dst_padded, cv.COLOR_BGR2GRAY)\n",
        "    mask_dst = (mask_dst == 0).astype(np.uint8)\n",
        "\n",
        "    # Ensure mask has three channels\n",
        "    mask_dst_3ch = cv.merge([mask_dst, mask_dst, mask_dst])\n",
        "\n",
        "    # Combine images by filling zeros in dst_padded with pixels from warped_image\n",
        "    combined_image = dst_padded.copy()\n",
        "    combined_image[mask_dst_3ch == 1] = warped_image[mask_dst_3ch == 1]\n",
        "\n",
        "    # Save the combined image\n",
        "    cv.imwrite(general_folder_path + 'aligned_image.jpg', combined_image)\n",
        "\n",
        "cv.imwrite(general_folder_path + 'final_panorama.jpg', combined_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "911d1e4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(40, 30))\n",
        "# Update and display the panorama with corner points\n",
        "plt.imshow(cv.cvtColor(combined_image, cv.COLOR_BGR2RGB))\n",
        "for _, row in image_corners_df.iterrows():\n",
        "    corners = row['corners']\n",
        "    x_coords, y_coords = corners[:, 0], corners[:, 1]\n",
        "    plt.plot(x_coords, y_coords, 'o-', label=os.path.basename(row['image_path']))\n",
        "    plt.fill(x_coords, y_coords, alpha=0.3)\n",
        "plt.axis('on')\n",
        "# plt.legend()  # Uncomment if you want to add a legend\n",
        "plt.show()\n",
        "\n",
        "# Save the df to a csv file\n",
        "image_corners_df.to_csv(general_folder_path + 'results/image_corners.csv', index=False)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03eccc20",
      "metadata": {},
      "outputs": [],
      "source": [
        "#############################################\n",
        "# Imports and Configuration\n",
        "#############################################\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import cv2 as cv\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as TF\n",
        "from tqdm.notebook import tqdm\n",
        "import math\n",
        "from PIL import Image\n",
        "\n",
        "from lightglue import LightGlue, DoGHardNet\n",
        "from lightglue.utils import load_image, match_pair\n",
        "\n",
        "# Set paths and constants\n",
        "GENERAL_FOLDER_PATH = '/home/oussama/Documents/EPFL/PDS_LUTS/'\n",
        "IMAGE_FOLDER = os.path.join(GENERAL_FOLDER_PATH, 'images_updated')\n",
        "PANORAMA_OUTPUT_PATH = os.path.join(GENERAL_FOLDER_PATH, 'panorama.jpg')\n",
        "RESULTS_FOLDER = os.path.join(GENERAL_FOLDER_PATH, 'results')\n",
        "if not os.path.exists(RESULTS_FOLDER):\n",
        "    os.makedirs(RESULTS_FOLDER)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Utility functions\n",
        "def rotate_image(image, angle):\n",
        "    \"\"\"Rotate a PIL image tensor by a given angle.\"\"\"\n",
        "    return TF.rotate(image, angle)\n",
        "\n",
        "def rotate_image1(image, angle):\n",
        "    \"\"\"\n",
        "    Rotate an image without cropping and add necessary padding to preserve all content.\n",
        "\n",
        "    Args:\n",
        "        image: A PIL Image or PyTorch tensor.\n",
        "        angle: Rotation angle in degrees (counterclockwise).\n",
        "\n",
        "    Returns:\n",
        "        Rotated image with padding to fit all content.\n",
        "    \"\"\"\n",
        "    # Convert to PIL Image if it's a tensor\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image = TF.to_pil_image(image)\n",
        "\n",
        "    # Get original dimensions\n",
        "    w, h = image.size\n",
        "\n",
        "    # Calculate new canvas size to fit the rotated image\n",
        "    angle_rad = math.radians(angle)\n",
        "    new_w = int(abs(w * math.cos(angle_rad)) + abs(h * math.sin(angle_rad)))\n",
        "    new_h = int(abs(w * math.sin(angle_rad)) + abs(h * math.cos(angle_rad)))\n",
        "\n",
        "    # Create a larger blank canvas with padding\n",
        "    canvas = Image.new(\"RGBA\", (new_w, new_h), (0, 0, 0, 0))\n",
        "\n",
        "    # Calculate the translation to center the original image\n",
        "    translation_x = (new_w - w) // 2\n",
        "    translation_y = (new_h - h) // 2\n",
        "\n",
        "    # Paste the original image into the center of the blank canvas\n",
        "    canvas.paste(image, (translation_x, translation_y))\n",
        "\n",
        "    # Rotate the entire canvas\n",
        "    rotated = canvas.rotate(angle, resample=Image.BICUBIC, expand=False)\n",
        "\n",
        "    # Convert back to RGB if the original image was RGB\n",
        "    if image.mode == \"RGB\":\n",
        "        rotated = rotated.convert(\"RGB\")\n",
        "\n",
        "    return rotated\n",
        "\n",
        "def compute_similarity_score(image1, image2, extractor, matcher):\n",
        "    \"\"\"Compute similarity score between two images based on matched keypoints.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        feats0, feats1, matches01 = match_pair(extractor, matcher, image1, image2)\n",
        "    points0 = feats0['keypoints'][matches01['matches'][..., 0]]\n",
        "    score = points0.shape[0]\n",
        "    del feats0, feats1, matches01, points0\n",
        "    torch.cuda.empty_cache()\n",
        "    return score\n",
        "\n",
        "def split_image_paths(image_paths):\n",
        "    \"\"\"\n",
        "    Splits the image_paths list into two halves:\n",
        "    - First half gets an extra frame if the total number of images is odd.\n",
        "    - Second half is reversed to start from the last image and go to the middle.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of image paths.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (first_half, second_half) - two lists of image paths.\n",
        "    \"\"\"\n",
        "    # Compute the midpoint\n",
        "    mid = (len(image_paths) + 1) // 2\n",
        "\n",
        "    # Split the list\n",
        "    first_half = image_paths[:mid]  # First half\n",
        "    second_half = image_paths[mid:][::-1]  # Second half, reversed\n",
        "\n",
        "    return first_half, second_half\n",
        "\n",
        "def warp_perspective_padded(src, dst, transf):\n",
        "    \"\"\"Warp 'src' image into 'dst' image using a homography 'transf' with padding.\"\"\"\n",
        "    src_h, src_w = src.shape[:2]\n",
        "    dst_h, dst_w = dst.shape[:2]\n",
        "\n",
        "    src_corners = np.float32([[0, 0],\n",
        "                              [src_w, 0],\n",
        "                              [src_w, src_h],\n",
        "                              [0, src_h]])\n",
        "    dst_corners = np.float32([[0, 0],\n",
        "                              [dst_w, 0],\n",
        "                              [dst_w, dst_h],\n",
        "                              [0, dst_h]])\n",
        "\n",
        "    src_corners_transformed = cv2.perspectiveTransform(src_corners[None, :, :], transf)[0]\n",
        "    all_corners = np.vstack((src_corners_transformed, dst_corners))\n",
        "\n",
        "    x_min, y_min = np.int32(all_corners.min(axis=0))\n",
        "    x_max, y_max = np.int32(all_corners.max(axis=0))\n",
        "\n",
        "    shift_x = -x_min\n",
        "    shift_y = -y_min\n",
        "    output_width = x_max - x_min\n",
        "    output_height = y_max - y_min\n",
        "\n",
        "    translation_matrix = np.array([\n",
        "        [1, 0, shift_x],\n",
        "        [0, 1, shift_y],\n",
        "        [0, 0, 1]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    new_transf = translation_matrix @ transf\n",
        "    warped = cv2.warpPerspective(src, new_transf, (output_width, output_height))\n",
        "    dst_pad = cv2.warpAffine(dst, translation_matrix[:2], (output_width, output_height))\n",
        "\n",
        "    anchorX = int(shift_x)\n",
        "    anchorY = int(shift_y)\n",
        "    sign = (anchorX > 0) or (anchorY > 0)\n",
        "    return dst_pad, warped, anchorX, anchorY, sign\n",
        "\n",
        "#############################################\n",
        "# Initialization\n",
        "#############################################\n",
        "\n",
        "# Feature extractor and matcher\n",
        "extractor = DoGHardNet(max_num_keypoints=None).eval().cuda()\n",
        "matcher = LightGlue(features='doghardnet').eval().cuda()\n",
        "\n",
        "start = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db243335",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import math\n",
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "# import torchvision.transforms.functional as TF\n",
        "# import cv2 as cv\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def rotate_image_with_padding(image, angle):\n",
        "#     \"\"\"\n",
        "#     Rotate an image without cropping and add necessary padding to preserve all content.\n",
        "\n",
        "#     Args:\n",
        "#         image: A PIL Image or PyTorch tensor.\n",
        "#         angle: Rotation angle in degrees (counterclockwise).\n",
        "\n",
        "#     Returns:\n",
        "#         Rotated image with padding to fit all content.\n",
        "#     \"\"\"\n",
        "#     # Convert to PIL Image if it's a tensor\n",
        "#     if isinstance(image, torch.Tensor):\n",
        "#         image = TF.to_pil_image(image)\n",
        "\n",
        "#     # Get original dimensions\n",
        "#     w, h = image.size\n",
        "\n",
        "#     # Calculate new canvas size to fit the rotated image\n",
        "#     angle_rad = math.radians(angle)\n",
        "#     new_w = int(abs(w * math.cos(angle_rad)) + abs(h * math.sin(angle_rad)))\n",
        "#     new_h = int(abs(w * math.sin(angle_rad)) + abs(h * math.cos(angle_rad)))\n",
        "\n",
        "#     # Create a larger blank canvas with padding\n",
        "#     canvas = Image.new(\"RGBA\", (new_w, new_h), (0, 0, 0, 0))\n",
        "\n",
        "#     # Calculate the translation to center the original image\n",
        "#     translation_x = (new_w - w) // 2\n",
        "#     translation_y = (new_h - h) // 2\n",
        "\n",
        "#     # Paste the original image into the center of the blank canvas\n",
        "#     canvas.paste(image, (translation_x, translation_y))\n",
        "\n",
        "#     # Rotate the entire canvas\n",
        "#     rotated = canvas.rotate(angle, resample=Image.BICUBIC, expand=False)\n",
        "\n",
        "#     # Convert back to RGB if the original image was RGB\n",
        "#     if image.mode == \"RGB\":\n",
        "#         rotated = rotated.convert(\"RGB\")\n",
        "\n",
        "#     return rotated\n",
        "# image10 = load_image(image_paths[-1])\n",
        "# image10 = rotate_image_with_padding(image10, 10)\n",
        "# image10 = cv.cvtColor(np.array(image10), cv.COLOR_RGB2BGR)\n",
        "# plt.imshow(cv.cvtColor(image10, cv.COLOR_BGR2RGB))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29cc1a28",
      "metadata": {},
      "outputs": [],
      "source": [
        "#############################################\n",
        "# Get all images to stitch\n",
        "#############################################\n",
        "\n",
        "# Load all images\n",
        "image_paths = glob.glob(os.path.join(IMAGE_FOLDER, '*.jpg'))\n",
        "image_paths.sort()  # Ensure consistent order\n",
        "\n",
        "# Select the first image as a reference\n",
        "indice = 0\n",
        "# image_paths = image_paths[indice:] + image_paths[:indice]\n",
        "image_path0 = image_paths[indice]\n",
        "\n",
        "# Save and load the first image in both cv and tensor form\n",
        "cv.imwrite(os.path.join(GENERAL_FOLDER_PATH, 'warped_image.jpg'), cv.imread(image_path0))\n",
        "image0 = load_image(image_path0)\n",
        "imocv0 = cv.imread(image_path0)\n",
        "\n",
        "# Prepare DataFrame to store image corners and frame numbers\n",
        "image_corners_df = pd.DataFrame(columns=['image_path', 'corners', 'frame_number'])\n",
        "\n",
        "# Compute corners of the first image\n",
        "first_image_corners = np.array([\n",
        "    [0, 0],\n",
        "    [imocv0.shape[1]-1, 0],\n",
        "    [imocv0.shape[1]-1, imocv0.shape[0]-1],\n",
        "    [0, imocv0.shape[0]-1]\n",
        "], dtype=np.int32)\n",
        "\n",
        "frame_number = os.path.splitext(os.path.basename(image_path0))[0]\n",
        "\n",
        "# Add the first image's corners directly\n",
        "new_row = pd.DataFrame({\n",
        "    'image_path': [image_path0],\n",
        "    'corners': [first_image_corners],\n",
        "    'frame_number': [frame_number]\n",
        "})\n",
        "image_corners_df = pd.concat([image_corners_df, new_row], ignore_index=True)# Define the maximum number of images to process (for demonstration)\n",
        "# For a real scenario, you can use: for idx in range(indice+1, len(image_paths)):\n",
        "for idx in tqdm(range(0 + 1, len(image_paths))):\n",
        "    if not start:\n",
        "        # After the first iteration, image0 is the \"warped_image.jpg\"\n",
        "        image_path0 = os.path.join(GENERAL_FOLDER_PATH, 'warped_image.jpg')\n",
        "\n",
        "    image0 = load_image(image_path0)\n",
        "    image_path1 = image_paths[idx]\n",
        "    image1 = load_image(image_path1)\n",
        "\n",
        "    # Determine best rotation angle\n",
        "    rotation_angles = range(0, 360, 45)\n",
        "    best_score, best_angle = -1, 0\n",
        "    best_rotated_image = None\n",
        "\n",
        "    for angle in rotation_angles:\n",
        "        rotated_image1 = rotate_image(image1, angle)\n",
        "        score = compute_similarity_score(image0, rotated_image1, extractor, matcher)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_angle = angle\n",
        "            best_rotated_image = rotated_image1\n",
        "\n",
        "    imocv0 = cv.imread(image_path0)\n",
        "    imocv1 = cv.cvtColor(np.array(TF.to_pil_image(best_rotated_image.cpu()).convert(\"RGB\")), cv.COLOR_RGB2BGR)\n",
        "\n",
        "    feats0, feats1, matches01 = match_pair(extractor, matcher, image0, best_rotated_image)\n",
        "    points0 = feats0['keypoints'][matches01['matches'][..., 0]].cpu().numpy()\n",
        "    points1 = feats1['keypoints'][matches01['matches'][..., 1]].cpu().numpy()\n",
        "\n",
        "    if points0.shape[0] < 4:\n",
        "        print(\"Not enough points to compute homography for image:\", image_path1)\n",
        "        continue\n",
        "\n",
        "    M, _ = cv.findHomography(points1, points0, cv.RANSAC, 5.0)\n",
        "    M_normalized = M / M[2, 2]\n",
        "    M = np.array([\n",
        "        [M_normalized[0, 0], M_normalized[0, 1], M_normalized[0, 2]],\n",
        "        [M_normalized[1, 0], M_normalized[1, 1], M_normalized[1, 2]],\n",
        "        [0,                  0,                  1]\n",
        "    ])\n",
        "\n",
        "    angle_rad = math.atan2(M_normalized[1, 0], M_normalized[0, 0])  # Returns the angle in radians\n",
        "    angle_deg = math.degrees(angle_rad) + best_angle\n",
        "    print(f\"Rotation angle: {angle_deg:.2f} degrees\")\n",
        "\n",
        "    dst_padded, warped_image, anchorX1, anchorY1, sign = warp_perspective_padded(imocv1, imocv0, M)\n",
        "\n",
        "    # If not the very first iteration, retrieve corners from the previous image\n",
        "    if not start:\n",
        "        before_last_key = image_corners_df['image_path'].iloc[-1]\n",
        "        warped_image_corners = image_corners_df.loc[\n",
        "            image_corners_df['image_path'] == before_last_key, 'corners'\n",
        "        ].values[0]\n",
        "    else:\n",
        "        # If it's the start, just use the first image's corners\n",
        "        warped_image_corners = image_corners_df.loc[\n",
        "            image_corners_df['image_path'] == image_path0, 'corners'\n",
        "        ].values[0]\n",
        "\n",
        "    x_coords, y_coords = warped_image_corners[:, 0], warped_image_corners[:, 1]\n",
        "    prev_corners = np.array([\n",
        "        [x_coords[0], y_coords[0]],\n",
        "        [x_coords[1], y_coords[1]],\n",
        "        [x_coords[2], y_coords[2]],\n",
        "        [x_coords[3], y_coords[3]]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    b_x_min, b_y_min = np.min(prev_corners, axis=0).astype(int)\n",
        "    b_x_max, b_y_max = np.max(prev_corners, axis=0).astype(int)\n",
        "\n",
        "    new_image_corners = np.array([\n",
        "        [0, 0],\n",
        "        [imocv1.shape[1], 0],\n",
        "        [imocv1.shape[1], imocv1.shape[0]],\n",
        "        [0, imocv1.shape[0]]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    transformed_corners = cv2.perspectiveTransform(np.array([new_image_corners], dtype=np.float32), M)[0]\n",
        "    adjusted_corners = transformed_corners + [anchorX1, anchorY1]\n",
        "\n",
        "    # Add new image corners\n",
        "    new_row = pd.DataFrame({\n",
        "        'image_path': [image_path1],\n",
        "        'corners': [adjusted_corners],\n",
        "        'frame_number': [os.path.splitext(os.path.basename(image_path1))[0]]\n",
        "    })\n",
        "    image_corners_df = pd.concat([image_corners_df, new_row], ignore_index=True)\n",
        "\n",
        "    if start:\n",
        "        # Adjust the first image's corners once we have anchorX1, anchorY1\n",
        "        idx0 = image_corners_df[image_corners_df['image_path'] == image_path0].index[0]\n",
        "        image_corners_df.at[idx0, 'corners'] += [anchorX1, anchorY1]\n",
        "        (anchorX, anchorY) = (0, 0)\n",
        "\n",
        "    # Overlay warped image onto padded destination\n",
        "    non_zero_mask = (warped_image > 0).astype(np.uint8)\n",
        "    dst_padded[non_zero_mask == 1] = warped_image[non_zero_mask == 1]\n",
        "\n",
        "    # Get last image's corners to crop the region of interest\n",
        "    last_key = image_corners_df['image_path'].iloc[-1]\n",
        "    warped_image_corners = image_corners_df.loc[image_corners_df['image_path'] == last_key, 'corners'].values[0]\n",
        "    x_coords, y_coords = warped_image_corners[:, 0], warped_image_corners[:, 1]\n",
        "    current_corners = np.array([\n",
        "        [x_coords[0], y_coords[0]],\n",
        "        [x_coords[1], y_coords[1]],\n",
        "        [x_coords[2], y_coords[2]],\n",
        "        [x_coords[3], y_coords[3]]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    x_min, y_min = np.min(current_corners, axis=0).astype(int)\n",
        "    x_max, y_max = np.max(current_corners, axis=0).astype(int)\n",
        "\n",
        "    # warped_image = warped_image[y_min:y_max, x_min:x_max]\n",
        "    # cv.imwrite(os.path.join(GENERAL_FOLDER_PATH, 'warped_image.jpg'), warped_image)\n",
        "    image2 = load_image(image_paths[idx])\n",
        "    image2 = rotate_image1(image2, -angle_deg)\n",
        "    cv.imwrite(GENERAL_FOLDER_PATH, 'warped_image.jpg', cv.cvtColor(np.array(image2), cv.COLOR_RGB2BGR))\n",
        "    cv.imwrite(PANORAMA_OUTPUT_PATH, dst_padded)\n",
        "\n",
        "    if start:\n",
        "        cv.imwrite(os.path.join(GENERAL_FOLDER_PATH, 'aligned_image.jpg'), cv.imread(PANORAMA_OUTPUT_PATH))\n",
        "\n",
        "    # Load current panorama and aligned image\n",
        "    current_panorama = cv.imread(PANORAMA_OUTPUT_PATH)\n",
        "    new_image = cv.imread(os.path.join(GENERAL_FOLDER_PATH, 'aligned_image.jpg'))\n",
        "\n",
        "    # Create translation matrix\n",
        "    translation_matrix = np.float32([\n",
        "        [1, 0, b_x_min - anchorX1],\n",
        "        [0, 1, b_y_min - anchorY1],\n",
        "        [0, 0, 1]\n",
        "    ])\n",
        "\n",
        "    if start:\n",
        "        # For the first step, no translation needed\n",
        "        translation_matrix = np.float32([\n",
        "            [1, 0, 0],\n",
        "            [0, 1, 0],\n",
        "            [0, 0, 1]\n",
        "        ])\n",
        "\n",
        "    dst_padded, warped_image, anchorX, anchorY, _ = warp_perspective_padded(current_panorama, new_image, translation_matrix)\n",
        "\n",
        "    # Update DataFrame for all previous images (except the newly added one)\n",
        "    idx_last = image_corners_df[image_corners_df['image_path'] == last_key].index[0]\n",
        "    if not start:\n",
        "        image_corners_df.at[idx_last, 'corners'] += [b_x_min - anchorX1 + anchorX, b_y_min - anchorY1 + anchorY]\n",
        "\n",
        "    for img_path in image_corners_df['image_path']:\n",
        "        if img_path != image_path1:\n",
        "            idx_img = image_corners_df[image_corners_df['image_path'] == img_path].index[0]\n",
        "            image_corners_df.at[idx_img, 'corners'] += [anchorX, anchorY]\n",
        "\n",
        "    start = False\n",
        "\n",
        "    # Combine images by filling zero pixels in dst_padded with warped_image pixels\n",
        "    mask_dst = cv.cvtColor(dst_padded, cv.COLOR_BGR2GRAY)\n",
        "    mask_dst = (mask_dst == 0).astype(np.uint8)\n",
        "    mask_dst_3ch = cv.merge([mask_dst, mask_dst, mask_dst])\n",
        "    combined_image = dst_padded.copy()\n",
        "    combined_image[mask_dst_3ch == 1] = warped_image[mask_dst_3ch == 1]\n",
        "\n",
        "    # Save the combined image as the newly aligned image\n",
        "    cv.imwrite(os.path.join(GENERAL_FOLDER_PATH, 'aligned_image.jpg'), combined_image)\n",
        "\n",
        "# Final panorama\n",
        "cv.imwrite(os.path.join(GENERAL_FOLDER_PATH, 'final_panorama.jpg'), combined_image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f596a99",
      "metadata": {},
      "source": [
        "## Updated two way stitching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a61d3a16",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # Refactored Panorama Stitching Code\n",
        "\n",
        "# %% [code]\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "import cv2 as cv\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from lightglue import LightGlue, SuperPoint, viz2d, DISK, SIFT, ALIKED, DoGHardNet\n",
        "from lightglue.utils import load_image, rbd, match_pair\n",
        "\n",
        "# %% [code]\n",
        "#######################################\n",
        "# Global Configuration & Setup\n",
        "#######################################\n",
        "general_folder_path = '/home/oussama/Documents/EPFL/PDS_LUTS/'\n",
        "output_path = os.path.join(general_folder_path, 'panorama.jpg')\n",
        "image_folder = os.path.join(general_folder_path, 'images_updated')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Utility functions\n",
        "def rotate_image(image, angle):\n",
        "    \"\"\"Rotate a PIL image tensor by a given angle.\"\"\"\n",
        "    return TF.rotate(image, angle)\n",
        "\n",
        "def rotate_image_preserve(image: torch.Tensor, angle: float) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Rotate a PyTorch image tensor by a specified angle without cropping,\n",
        "    adding necessary padding to preserve all content.\n",
        "    \"\"\"\n",
        "    device = image.device\n",
        "    image_np = image.permute(1, 2, 0).cpu().numpy()\n",
        "    if image_np.max() <= 1:\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "    h, w = image_np.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    cos_val = abs(rotation_matrix[0, 0])\n",
        "    sin_val = abs(rotation_matrix[0, 1])\n",
        "\n",
        "    new_w = int(h * sin_val + w * cos_val)\n",
        "    new_h = int(h * cos_val + w * sin_val)\n",
        "\n",
        "    rotation_matrix[0, 2] += (new_w / 2) - center[0]\n",
        "    rotation_matrix[1, 2] += (new_h / 2) - center[1]\n",
        "\n",
        "    rotated_image_np = cv2.warpAffine(\n",
        "        image_np, rotation_matrix, (new_w, new_h),\n",
        "        flags=cv2.INTER_CUBIC,\n",
        "        borderMode=cv2.BORDER_CONSTANT,\n",
        "        borderValue=(0, 0, 0)\n",
        "    )\n",
        "\n",
        "    rotated_image_tensor = torch.from_numpy(rotated_image_np).permute(2, 0, 1).float()\n",
        "    if rotated_image_tensor.max() > 1:\n",
        "        rotated_image_tensor /= 255.0\n",
        "\n",
        "    return rotated_image_tensor.to(device)\n",
        "\n",
        "def compute_similarity_score(image1, image2, extractor, matcher):\n",
        "    \"\"\"Compute similarity score between two images based on matched keypoints.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        feats0, feats1, matches01 = match_pair(extractor, matcher, image1, image2)\n",
        "    points0 = feats0['keypoints'][matches01['matches'][..., 0]]\n",
        "    score = points0.shape[0]\n",
        "    del feats0, feats1, matches01, points0\n",
        "    torch.cuda.empty_cache()\n",
        "    return score\n",
        "\n",
        "def split_image_paths(image_paths):\n",
        "    \"\"\"\n",
        "    Splits the image_paths list into two halves:\n",
        "    - First half gets an extra frame if the total number of images is odd.\n",
        "    - Second half is reversed to start from the last image and go to the middle.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list): List of image paths.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (first_half, second_half) - two lists of image paths.\n",
        "    \"\"\"\n",
        "    # Compute the midpoint\n",
        "    mid = (len(image_paths) + 1) // 2\n",
        "\n",
        "    # Split the list\n",
        "    first_half = image_paths[:mid]  # First half\n",
        "    second_half = image_paths[mid:][::-1]  # Second half, reversed\n",
        "\n",
        "    return first_half, second_half\n",
        "\n",
        "def warp_perspective_padded(src, dst, transf):\n",
        "    \"\"\"Warp 'src' image into 'dst' image using a homography 'transf' with padding.\"\"\"\n",
        "    src_h, src_w = src.shape[:2]\n",
        "    dst_h, dst_w = dst.shape[:2]\n",
        "\n",
        "    src_corners = np.float32([[0, 0],\n",
        "                              [src_w, 0],\n",
        "                              [src_w, src_h],\n",
        "                              [0, src_h]])\n",
        "    dst_corners = np.float32([[0, 0],\n",
        "                              [dst_w, 0],\n",
        "                              [dst_w, dst_h],\n",
        "                              [0, dst_h]])\n",
        "\n",
        "    src_corners_transformed = cv2.perspectiveTransform(src_corners[None, :, :], transf)[0]\n",
        "    all_corners = np.vstack((src_corners_transformed, dst_corners))\n",
        "\n",
        "    x_min, y_min = np.int32(all_corners.min(axis=0))\n",
        "    x_max, y_max = np.int32(all_corners.max(axis=0))\n",
        "\n",
        "    shift_x = -x_min\n",
        "    shift_y = -y_min\n",
        "    output_width = x_max - x_min\n",
        "    output_height = y_max - y_min\n",
        "\n",
        "    translation_matrix = np.array([\n",
        "        [1, 0, shift_x],\n",
        "        [0, 1, shift_y],\n",
        "        [0, 0, 1]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    new_transf = translation_matrix @ transf\n",
        "    warped = cv2.warpPerspective(src, new_transf, (output_width, output_height))\n",
        "    dst_pad = cv2.warpAffine(dst, translation_matrix[:2], (output_width, output_height))\n",
        "\n",
        "    anchorX = int(shift_x)\n",
        "    anchorY = int(shift_y)\n",
        "    return dst_pad, warped, anchorX, anchorY\n",
        "\n",
        "def split_image_paths(image_paths: list) -> (list, list):\n",
        "    \"\"\"\n",
        "    Splits the image_paths list into two halves:\n",
        "    - First half gets an extra frame if the total number of images is odd.\n",
        "    - Second half is reversed (so that it starts from the last image and goes towards the middle).\n",
        "    \"\"\"\n",
        "    mid = (len(image_paths) + 1) // 2\n",
        "    first_half = image_paths[:mid]\n",
        "    second_half = image_paths[mid:][::-1]\n",
        "    return first_half, second_half\n",
        "\n",
        "def choose_best_rotation(image0: torch.Tensor, image1: torch.Tensor, extractor, matcher, angles=range(0,360,45)):\n",
        "    \"\"\"Find the best rotation angle for image1 to match image0.\"\"\"\n",
        "    best_score, best_angle = -1, 0\n",
        "    for angle in angles:\n",
        "        rotated = rotate_image(image1, angle)\n",
        "        score = compute_similarity_score(image0, rotated, extractor, matcher)\n",
        "        if score > best_score:\n",
        "            best_score, best_angle = score, angle\n",
        "    return best_angle\n",
        "\n",
        "def update_corners_df(image_corners_df: pd.DataFrame, image_path: str, corners: np.ndarray) -> pd.DataFrame:\n",
        "    \"\"\"Add a new row to the corners DataFrame with provided image path and corners.\"\"\"\n",
        "    frame_number = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    new_row = pd.DataFrame({\n",
        "        'image_path': [image_path],\n",
        "        'corners': [corners],\n",
        "        'frame_number': [frame_number]\n",
        "    })\n",
        "    return pd.concat([image_corners_df, new_row], ignore_index=True)\n",
        "\n",
        "def overlay_images(base_img: np.ndarray, overlay_img: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Overlay overlay_img onto base_img wherever base_img is zero.\"\"\"\n",
        "    mask_dst = cv2.cvtColor(base_img, cv2.COLOR_BGR2GRAY)\n",
        "    mask_dst = (mask_dst == 0).astype(np.uint8)\n",
        "    mask_dst_3ch = cv2.merge([mask_dst, mask_dst, mask_dst])\n",
        "    combined = base_img.copy()\n",
        "    combined[mask_dst_3ch == 1] = overlay_img[mask_dst_3ch == 1]\n",
        "    return combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "20e9f1e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "#######################################\n",
        "# Initialization\n",
        "#######################################\n",
        "\n",
        "# Initialize feature extractor and matcher\n",
        "extractor = DoGHardNet(max_num_keypoints=None).eval().cuda()\n",
        "matcher = LightGlue(features='doghardnet').eval().cuda()\n",
        "\n",
        "# Get all .jpg files in the folder, sorted if necessary\n",
        "image_paths = sorted(glob.glob(os.path.join(image_folder, '*.jpg')))\n",
        "indice = 0\n",
        "image_paths = image_paths[indice:] + image_paths[:indice]\n",
        "\n",
        "# Load first image and set up DataFrame\n",
        "image_path0 = image_paths[0]\n",
        "cv.imwrite(os.path.join(general_folder_path, 'warped_image.jpg'), cv2.imread(image_path0))\n",
        "image0 = load_image(image_path0)\n",
        "\n",
        "image_corners_df = pd.DataFrame(columns=['image_path', 'corners', 'frame_number'])\n",
        "\n",
        "first_image_corners = np.array([[0, 0],\n",
        "                                [image0.shape[2]-1, 0],\n",
        "                                [image0.shape[2]-1, image0.shape[1]-1],\n",
        "                                [0, image0.shape[1]-1]], dtype=np.int32)\n",
        "\n",
        "image_corners_df = update_corners_df(image_corners_df, image_path0, first_image_corners)\n",
        "first_half, second_half = split_image_paths(image_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2054132d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing first half of images...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6b9ba9f02114e09b8b378c19a2f3085",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#######################################\n",
        "# Stitching First Half\n",
        "#######################################\n",
        "start = True\n",
        "\n",
        "print(\"Processing first half of images...\")\n",
        "for idx in tqdm(range(indice + 1, 3)):\n",
        "    if not start:\n",
        "        image_path0 = os.path.join(general_folder_path, 'warped_image.jpg')\n",
        "    image0 = load_image(image_path0)\n",
        "\n",
        "    image_path1 = first_half[idx]\n",
        "    image1 = load_image(image_path1)\n",
        "\n",
        "    # Determine best rotation\n",
        "    best_angle = choose_best_rotation(image0, image1, extractor, matcher)\n",
        "    best_rotated_image = rotate_image(image1, best_angle)\n",
        "\n",
        "    # Prepare images for final stitching\n",
        "    imocv0 = cv2.imread(image_path0)\n",
        "    imocv1 = cv2.cvtColor(np.array(TF.to_pil_image(best_rotated_image.cpu()).convert(\"RGB\")), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Match and compute homography\n",
        "    feats0, feats1, matches01 = match_pair(extractor, matcher, image0, best_rotated_image)\n",
        "    points0 = feats0['keypoints'][matches01['matches'][..., 0]].cpu().numpy()\n",
        "    points1 = feats1['keypoints'][matches01['matches'][..., 1]].cpu().numpy()\n",
        "\n",
        "    if points0.shape[0] < 4:\n",
        "        print(\"Not enough points to compute homography.\")\n",
        "        continue\n",
        "\n",
        "    M, _ = cv2.findHomography(points1, points0, cv2.RANSAC, 5.0)\n",
        "\n",
        "    M_normalized = M / M[2, 2]\n",
        "    M = np.array([\n",
        "        [M_normalized[0, 0], M_normalized[0, 1], M_normalized[0, 2]],\n",
        "        [M_normalized[1, 0], M_normalized[1, 1], M_normalized[1, 2]],\n",
        "        [M_normalized[2, 0],                 0,                 1]\n",
        "    ])\n",
        "\n",
        "    angle_rad = math.atan2(M[1, 0], M[0, 0])\n",
        "    angle_deg = math.degrees(angle_rad) - best_angle\n",
        "\n",
        "    dst_padded, warped_image, anchorX1, anchorY1 = warp_perspective_padded(imocv1, imocv0, M)\n",
        "\n",
        "    before_last_key = image_corners_df['image_path'].iloc[-1]\n",
        "    prev_corners = image_corners_df.loc[image_corners_df['image_path'] == before_last_key, 'corners'].values[0]\n",
        "    x_coords, y_coords = prev_corners[:, 0], prev_corners[:, 1]\n",
        "\n",
        "    new_image_corners = np.array([[0, 0],\n",
        "                                  [imocv1.shape[1], 0],\n",
        "                                  [imocv1.shape[1], imocv1.shape[0]],\n",
        "                                  [0, imocv1.shape[0]]], dtype=np.float32)\n",
        "\n",
        "    transformed_corners = cv2.perspectiveTransform(np.array([new_image_corners], dtype=np.float32), M)[0]\n",
        "    adjusted_corners = transformed_corners + [anchorX1, anchorY1]\n",
        "\n",
        "    image_corners_df = update_corners_df(image_corners_df, image_path1, adjusted_corners)\n",
        "\n",
        "    if start:\n",
        "        idx0 = image_corners_df[image_corners_df['image_path'] == image_path0].index[0]\n",
        "        image_corners_df.at[idx0, 'corners'] += [anchorX1, anchorY1]\n",
        "\n",
        "    # Overlay images\n",
        "    non_zero_mask = (warped_image > 0).astype(np.uint8)\n",
        "    dst_padded[non_zero_mask == 1] = warped_image[non_zero_mask == 1]\n",
        "\n",
        "    last_key = image_corners_df['image_path'].iloc[-1]\n",
        "    last_corners = image_corners_df.loc[image_corners_df['image_path'] == last_key, 'corners'].values[0]\n",
        "    lx, ly = last_corners[:, 0], last_corners[:, 1]\n",
        "    x_min, y_min = np.min(np.array([lx, ly]), axis=1).astype(int)\n",
        "    x_max, y_max = np.max(np.array([lx, ly]), axis=1).astype(int)\n",
        "\n",
        "    # Crop the region of interest\n",
        "    warped_image_cropped = warped_image[y_min:y_max, x_min:x_max]\n",
        "    cv2.imwrite(os.path.join(general_folder_path, 'warped_image.jpg'), warped_image_cropped)\n",
        "    cv2.imwrite(os.path.join(general_folder_path, 'panorama.jpg'), dst_padded)\n",
        "\n",
        "    if start:\n",
        "        cv2.imwrite(os.path.join(general_folder_path, 'aligned_image.jpg'),\n",
        "                    cv2.imread(os.path.join(general_folder_path, 'panorama.jpg')))\n",
        "\n",
        "    current_panorama = cv2.imread(os.path.join(general_folder_path, 'panorama.jpg'))\n",
        "    new_image_aligned = cv2.imread(os.path.join(general_folder_path, 'aligned_image.jpg'))\n",
        "\n",
        "    translation_matrix = np.float32([\n",
        "        [1, 0, x_min - anchorX1],\n",
        "        [0, 1, y_min - anchorY1],\n",
        "        [0, 0, 1]\n",
        "    ])\n",
        "\n",
        "    if start:\n",
        "        # For the first iteration, no translation is needed\n",
        "        translation_matrix = np.float32([\n",
        "            [1, 0, 0],\n",
        "            [0, 1, 0],\n",
        "            [0, 0, 1]\n",
        "        ])\n",
        "\n",
        "    dst_padded_trans, warped_image_trans, anchorX, anchorY = warp_perspective_padded(current_panorama, new_image_aligned, translation_matrix)\n",
        "\n",
        "    # Update corners\n",
        "    idx_last = image_corners_df[image_corners_df['image_path'] == last_key].index[0]\n",
        "    if not start:\n",
        "        image_corners_df.at[idx_last, 'corners'] += [x_min - anchorX1 + anchorX, y_min - anchorY1 + anchorY]\n",
        "\n",
        "    for img_path in image_corners_df['image_path']:\n",
        "        if img_path != image_path1:\n",
        "            idx_img = image_corners_df[image_corners_df['image_path'] == img_path].index[0]\n",
        "            image_corners_df.at[idx_img, 'corners'] += [anchorX, anchorY]\n",
        "\n",
        "    start = False\n",
        "\n",
        "    combined_image = overlay_images(dst_padded_trans, warped_image_trans)\n",
        "    cv2.imwrite(os.path.join(general_folder_path, 'aligned_image.jpg'), combined_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ff3a58d8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing second half of images...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bfc64652efa49959d6885ce457d406b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[ WARN:0@46.273] global loadsave.cpp:241 findDecoder imread_('/home/oussama/Documents/EPFL/PDS_LUTS/aligned_image.jpg'): can't open/read file: check file path/integrity\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 115\u001b[0m\n\u001b[1;32m    107\u001b[0m new_image \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(general_folder_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maligned_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Ensure this exists or handle it\u001b[39;00m\n\u001b[1;32m    109\u001b[0m translation_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([\n\u001b[1;32m    110\u001b[0m     [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, b_x_min \u001b[38;5;241m-\u001b[39m anchorX1],\n\u001b[1;32m    111\u001b[0m     [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, b_y_min \u001b[38;5;241m-\u001b[39m anchorY1],\n\u001b[1;32m    112\u001b[0m     [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    113\u001b[0m ])\n\u001b[0;32m--> 115\u001b[0m dst_padded_tr, warped_image_tr, anchorX, anchorY \u001b[38;5;241m=\u001b[39m \u001b[43mwarp_perspective_padded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_panorama\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslation_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Update corners after translation\u001b[39;00m\n\u001b[1;32m    118\u001b[0m idx_last \u001b[38;5;241m=\u001b[39m image_corners_df[image_corners_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m last_key]\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m]\n",
            "Cell \u001b[0;32mIn[1], line 105\u001b[0m, in \u001b[0;36mwarp_perspective_padded\u001b[0;34m(src, dst, transf)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warp 'src' image into 'dst' image using a homography 'transf' with padding.\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m src_h, src_w \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m--> 105\u001b[0m dst_h, dst_w \u001b[38;5;241m=\u001b[39m \u001b[43mdst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    107\u001b[0m src_corners \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    108\u001b[0m                           [src_w, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    109\u001b[0m                           [src_w, src_h],\n\u001b[1;32m    110\u001b[0m                           [\u001b[38;5;241m0\u001b[39m, src_h]])\n\u001b[1;32m    111\u001b[0m dst_corners \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    112\u001b[0m                           [dst_w, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    113\u001b[0m                           [dst_w, dst_h],\n\u001b[1;32m    114\u001b[0m                           [\u001b[38;5;241m0\u001b[39m, dst_h]])\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "#######################################\n",
        "# Stitching Second Half\n",
        "#######################################\n",
        "indice = 0\n",
        "start = True\n",
        "\n",
        "print(\"Processing second half of images...\")\n",
        "for idx in tqdm(range(indice + 1, len(second_half))):\n",
        "    # Determine the reference image (anchor) and the target image\n",
        "    image_path0 = (general_folder_path + 'warped_image.jpg') if not start else image_paths[0]\n",
        "    image_path1 = second_half[idx]\n",
        "\n",
        "    image0 = load_image(image_path0)\n",
        "    image1 = load_image(image_path1)\n",
        "\n",
        "    # Find best rotation angle for image1 to match image0\n",
        "    best_angle = choose_best_rotation(image0, image1, extractor, matcher)\n",
        "    best_rotated_image = rotate_image(image1, best_angle)\n",
        "\n",
        "    # Extract features and matches\n",
        "    feats0, feats1, matches01 = match_pair(extractor, matcher, image0, best_rotated_image)\n",
        "    points0 = feats0['keypoints'][matches01['matches'][..., 0]].cpu().numpy()\n",
        "    points1 = feats1['keypoints'][matches01['matches'][..., 1]].cpu().numpy()\n",
        "\n",
        "    if points0.shape[0] < 4:\n",
        "        print(\"Not enough points to compute homography.\")\n",
        "        continue\n",
        "\n",
        "    # Compute homography\n",
        "    M, _ = cv.findHomography(points1, points0, cv.RANSAC, 5.0)\n",
        "\n",
        "    # Normalize and adjust homography matrix\n",
        "    M_normalized = M / M[2, 2]\n",
        "    M_adjusted = np.array([\n",
        "        [M_normalized[0, 0], M_normalized[0, 1], M_normalized[0, 2]],\n",
        "        [M_normalized[1, 0], M_normalized[1, 1], M_normalized[1, 2]],\n",
        "        [M_normalized[2, 0],             0,             1]\n",
        "    ])\n",
        "    M = M_adjusted\n",
        "\n",
        "    # Compute angle in degrees\n",
        "    angle_rad = math.atan2(M[1, 0], M[0, 0])\n",
        "    angle_deg = math.degrees(angle_rad) + best_angle\n",
        "\n",
        "    # Prepare OpenCV images\n",
        "    imocv0 = cv.imread(image_path0)\n",
        "    imocv1 = cv.cvtColor(np.array(TF.to_pil_image(best_rotated_image.cpu()).convert(\"RGB\")), cv.COLOR_RGB2BGR)\n",
        "\n",
        "    # Warp perspective\n",
        "    dst_padded, warped_image, anchorX1, anchorY1 = warp_perspective_padded(imocv1, imocv0, M)\n",
        "\n",
        "    # Retrieve corners from image_corners_df\n",
        "    if start:\n",
        "        before_last_key = image_corners_df['image_path'].iloc[0]\n",
        "    else:\n",
        "        before_last_key = image_corners_df['image_path'].iloc[-1]\n",
        "\n",
        "    warped_image_corners = image_corners_df.loc[image_corners_df['image_path'] == before_last_key, 'corners'].values[0]\n",
        "    x_coords, y_coords = warped_image_corners[:, 0], warped_image_corners[:, 1]\n",
        "\n",
        "    corners = np.array([[x_coords[0], y_coords[0]],\n",
        "                        [x_coords[1], y_coords[1]],\n",
        "                        [x_coords[2], y_coords[2]],\n",
        "                        [x_coords[3], y_coords[3]]], dtype=np.float32)\n",
        "\n",
        "    b_x_min, b_y_min = np.min(corners, axis=0).astype(int)\n",
        "    b_x_max, b_y_max = np.max(corners, axis=0).astype(int)\n",
        "\n",
        "    # Define new image corners and transform them\n",
        "    new_image_corners = np.array([[0, 0],\n",
        "                                  [imocv1.shape[1], 0],\n",
        "                                  [imocv1.shape[1], imocv1.shape[0]],\n",
        "                                  [0, imocv1.shape[0]]], dtype=np.float32)\n",
        "\n",
        "    transformed_corners = cv.perspectiveTransform(np.array([new_image_corners], dtype=np.float32), M)[0]\n",
        "    adjusted_corners = transformed_corners + [anchorX1, anchorY1]\n",
        "\n",
        "    # Update corners DF\n",
        "    image_corners_df = update_corners_df(image_corners_df, image_path1, adjusted_corners)\n",
        "\n",
        "    # Overlay warped image onto the padded destination\n",
        "    non_zero_mask = (warped_image > 0).astype(np.uint8)\n",
        "    dst_padded[non_zero_mask == 1] = warped_image[non_zero_mask == 1]\n",
        "\n",
        "    # Get last and before last keys\n",
        "    last_key = image_corners_df['image_path'].iloc[-1]\n",
        "    warped_image_corners = image_corners_df.loc[image_corners_df['image_path'] == last_key, 'corners'].values[0]\n",
        "    x_coords, y_coords = warped_image_corners[:, 0], warped_image_corners[:, 1]\n",
        "\n",
        "    corners = np.array([[x_coords[0], y_coords[0]],\n",
        "                        [x_coords[1], y_coords[1]],\n",
        "                        [x_coords[2], y_coords[2]],\n",
        "                        [x_coords[3], y_coords[3]]], dtype=np.float32)\n",
        "\n",
        "    x_min, y_min = np.min(corners, axis=0).astype(int)\n",
        "    x_max, y_max = np.max(corners, axis=0).astype(int)\n",
        "\n",
        "    # Crop the region of interest\n",
        "    cropped_warped_image = warped_image[y_min:y_max, x_min:x_max]\n",
        "    cv.imwrite(general_folder_path + 'warped_image.jpg', cropped_warped_image)\n",
        "\n",
        "    # Save current panorama\n",
        "    cv.imwrite(general_folder_path + 'panorama.jpg', dst_padded)\n",
        "\n",
        "    # Apply translation to align images\n",
        "    current_panorama = cv.imread(general_folder_path + 'panorama.jpg')\n",
        "    new_image = cv.imread(general_folder_path + 'aligned_image.jpg')  # Ensure this exists or handle it\n",
        "\n",
        "    translation_matrix = np.float32([\n",
        "        [1, 0, b_x_min - anchorX1],\n",
        "        [0, 1, b_y_min - anchorY1],\n",
        "        [0, 0, 1]\n",
        "    ])\n",
        "\n",
        "    dst_padded_tr, warped_image_tr, anchorX, anchorY = warp_perspective_padded(current_panorama, new_image, translation_matrix)\n",
        "\n",
        "    # Update corners after translation\n",
        "    idx_last = image_corners_df[image_corners_df['image_path'] == last_key].index[0]\n",
        "    image_corners_df.at[idx_last, 'corners'] += [b_x_min - anchorX1 + anchorX, b_y_min - anchorY1 + anchorY]\n",
        "\n",
        "    # Shift all other images except the current by the translation offset\n",
        "    for img_path in image_corners_df['image_path']:\n",
        "        if img_path != image_path1:\n",
        "            idx_other = image_corners_df[image_corners_df['image_path'] == img_path].index[0]\n",
        "            image_corners_df.at[idx_other, 'corners'] += [anchorX, anchorY]\n",
        "\n",
        "    start = False\n",
        "\n",
        "    # Combine images\n",
        "    combined_image = overlay_images(dst_padded_tr, warped_image_tr)\n",
        "    cv.imwrite(general_folder_path + 'aligned_image.jpg', combined_image)\n",
        "\n",
        "# Save the final panorama\n",
        "cv.imwrite(os.path.join(general_folder_path, 'final_panorama.jpg'), combined_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd6cf42",
      "metadata": {},
      "outputs": [],
      "source": [
        "#######################################\n",
        "# Display & Save Results\n",
        "#######################################\n",
        "plt.figure(figsize=(40, 30))\n",
        "plt.imshow(cv2.cvtColor(combined_image, cv2.COLOR_BGR2RGB))\n",
        "for _, row in image_corners_df.iterrows():\n",
        "    corners = row['corners']\n",
        "    x_coords, y_coords = corners[:, 0], corners[:, 1]\n",
        "    plt.plot(x_coords, y_coords, 'o-', label=os.path.basename(row['image_path']))\n",
        "    plt.fill(x_coords, y_coords, alpha=0.3)\n",
        "plt.axis('on')\n",
        "# plt.legend()  # Uncomment if you want a legend\n",
        "plt.show()\n",
        "\n",
        "image_corners_df.to_csv(os.path.join(general_folder_path, 'results/image_corners.csv'), index=False)\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "179e8ce7",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "luts",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
