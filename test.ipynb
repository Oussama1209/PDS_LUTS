{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch  \n",
    "\n",
    "from lightglue import LightGlue, SuperPoint\n",
    "from lightglue.utils import load_image, rbd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to MPS if available, otherwise fallback to CPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to crop, trim, zoom, and change the resolution of the video\n",
    "def crop_trim_zoom_change_resolution(input_video, output_video, zoom_ratio, start_time_in_seconds, duration_in_seconds, target_resolution=(1920, 1080)):\n",
    "    # Load the video\n",
    "    video = VideoFileClip(input_video)\n",
    "    \n",
    "    # Check if the start time is within the video's duration\n",
    "    print(f\"Video duration: {video.duration} seconds\")  # Debug: Show video duration\n",
    "    if start_time_in_seconds >= video.duration:\n",
    "        raise ValueError(\"Start time exceeds the video length.\")\n",
    "    \n",
    "    # Calculate the end time based on the start time and duration\n",
    "    end_time_in_seconds = start_time_in_seconds + duration_in_seconds\n",
    "    \n",
    "    # Trim the video to the specified start time and duration\n",
    "    if end_time_in_seconds <= video.duration:\n",
    "        video = video.subclip(start_time_in_seconds, end_time_in_seconds)\n",
    "    else:\n",
    "        print(\"Warning: Requested end time exceeds video length. Using the remaining duration.\")\n",
    "        video = video.subclip(start_time_in_seconds, video.duration)\n",
    "\n",
    "    # Get original video dimensions and FPS\n",
    "    original_width, original_height = video.size\n",
    "    fps = video.fps\n",
    "    print(f\"Original video size: {original_width}x{original_height}\")  # Debug: Show original size\n",
    "    \n",
    "    # Check if FPS is None, and set a default if necessary\n",
    "    if fps is None:\n",
    "        print(\"Warning: FPS could not be read from the video. Setting default FPS to 30.\")\n",
    "        fps = 30.0  # Set a default FPS value\n",
    "    else:\n",
    "        print(f\"Original FPS: {fps}\")  # Debug: Show FPS\n",
    "    \n",
    "    # Calculate the new width and height based on the zoom ratio\n",
    "    new_width = int(original_width / zoom_ratio)\n",
    "    new_height = int(original_height / zoom_ratio)\n",
    "    print(f\"Zoom ratio: {zoom_ratio}\")  # Debug: Show zoom ratio\n",
    "    print(f\"Cropped video size: {new_width}x{new_height}\")  # Debug: Show cropped size\n",
    "    \n",
    "    # Calculate the coordinates to crop the video so that the crop is centered\n",
    "    x1 = (original_width - new_width) // 2\n",
    "    y1 = (original_height - new_height) // 2\n",
    "    x2 = x1 + new_width\n",
    "    y2 = y1 + new_height\n",
    "    \n",
    "    # Crop the video and center it\n",
    "    cropped_video = video.crop(x1=x1, y1=y1, x2=x2, y2=y2)\n",
    "    \n",
    "    # Resize the cropped video to the target resolution (e.g., 1920x1080)\n",
    "    print(f\"Target resolution: {target_resolution}\")  # Debug: Show target resolution\n",
    "    resized_video = cropped_video.resize(target_resolution)\n",
    "    \n",
    "    # Write the cropped, trimmed, zoomed, and resized video to the output file with the specified FPS\n",
    "    resized_video.write_videofile(output_video, codec='libx264', fps=fps)\n",
    "\n",
    "# Path to the input video\n",
    "input_video = '/home/oussama/Documents/EPFL/PDS_LUTS/Dataset/DJI_0763.MOV'\n",
    "input_video_path = Path(input_video)\n",
    "if not input_video_path.exists():\n",
    "    raise FileNotFoundError(f\"Input video not found: {input_video_path}\")\n",
    "\n",
    "# Path to the output video\n",
    "output_video = 'Dataset/DJI_0763_output_trimmed.mp4'\n",
    "\n",
    "# Zoom ratio (e.g., 2.0 means the cropped area is 50% of the original size)\n",
    "zoom_ratio = 1.0\n",
    "\n",
    "# Starting time (in seconds) to begin the trimming\n",
    "start_time_in_seconds = 8  # Start the video after the first 120 seconds\n",
    "\n",
    "# Duration in seconds to keep from the video\n",
    "duration_in_seconds = 8  # Keep 90 seconds after the start\n",
    "\n",
    "# Target resolution (1920x1080)\n",
    "target_resolution = (3840, 2160)\n",
    "\n",
    "# Crop, trim, zoom, and change the resolution of the video\n",
    "crop_trim_zoom_change_resolution(\n",
    "    input_video=str(input_video_path), \n",
    "    output_video=output_video, \n",
    "    zoom_ratio=zoom_ratio, \n",
    "    start_time_in_seconds=start_time_in_seconds, \n",
    "    duration_in_seconds=duration_in_seconds, \n",
    "    target_resolution=target_resolution\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "general_path = '/home/oussama/Documents/EPFL/PDS_LUTS/'\n",
    "\n",
    "# Function to delete all existing files in the output folder\n",
    "def clear_folder(folder):\n",
    "    files = glob.glob(os.path.join(folder, '*'))\n",
    "    for f in files:\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except OSError as e:\n",
    "            print(f\"Error: {f} : {e.strerror}\")\n",
    "\n",
    "# Step 1: Extract frames and save to 'images' folder\n",
    "def extract_frames(video_path, output_folder, frame_interval=250):\n",
    "    # Clear existing files in the output folder\n",
    "    clear_folder(output_folder)\n",
    "    \n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}.\")\n",
    "        return\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    frame_idx = 0\n",
    "    saved_frames = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_idx % frame_interval == 0:\n",
    "            cv2.imwrite(os.path.join(output_folder, f'{str(frame_idx+200).zfill(4)}.jpg'), frame)\n",
    "            saved_frames += 1\n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "    print(f\"Extracted {saved_frames} frames from the video.\")\n",
    "\n",
    "def parse_srt_to_dataframe(srt_file):\n",
    "    # Define the data structure\n",
    "    data = {\n",
    "        'FrameCnt': [], 'Start_Time': [], 'End_Time': [], 'DiffTime_ms': [],\n",
    "        'ISO': [], 'Shutter': [], 'Fnum': [], 'EV': [], 'CT': [], \n",
    "        'Color_Mode': [], 'Focal_Length': [], 'Latitude': [], \n",
    "        'Longitude': [], 'Altitude': [], 'Image': [], 'Resolution_B': [], 'Resolution_S': [],\n",
    "        'Corners_B': [], 'Corners_S': [], 'Homography': [], 'Neighbors': [],\n",
    "    }\n",
    "\n",
    "    # Read and parse the SRT file\n",
    "    with open(srt_file, 'r') as file:\n",
    "        content = file.read()\n",
    "        blocks = content.split('\\n\\n')  # Split into blocks by double newlines\n",
    "\n",
    "        for block in blocks:\n",
    "            # Match each field within the block\n",
    "            frame_count = re.search(r'FrameCnt : (\\d+)', block)\n",
    "            diff_time = re.search(r'DiffTime : (\\d+)ms', block)\n",
    "            time_match = re.search(r'(\\d{2}:\\d{2}:\\d{2},\\d{3}) --> (\\d{2}:\\d{2}:\\d{2},\\d{3})', block)\n",
    "            iso = re.search(r'\\[iso : (\\d+)\\]', block)\n",
    "            shutter = re.search(r'\\[shutter : ([\\d/\\.]+)\\]', block)\n",
    "            fnum = re.search(r'\\[fnum : (\\d+)\\]', block)\n",
    "            ev = re.search(r'\\[ev : ([\\d\\.\\-]+)\\]', block)\n",
    "            ct = re.search(r'\\[ct : (\\d+)\\]', block)\n",
    "            color_mode = re.search(r'\\[color_md : (.*?)\\]', block)\n",
    "            focal_len = re.search(r'\\[focal_len : (\\d+)\\]', block)\n",
    "            latitude = re.search(r'\\[latitude : ([-\\d.]+)\\]', block)\n",
    "            longitude = re.search(r'\\[longtitude : ([-\\d.]+)\\]', block)  # Using provided typo\n",
    "            altitude = re.search(r'\\[altitude: ([-\\d.]+)\\]', block)\n",
    "\n",
    "            # Extract time data if available\n",
    "            if time_match:\n",
    "                start_time, end_time = time_match.groups()\n",
    "            else:\n",
    "                start_time, end_time = None, None\n",
    "\n",
    "            # Append data to dictionary, handling None values where needed\n",
    "            data['FrameCnt'].append(int(frame_count.group(1)) if frame_count else None)\n",
    "            data['Start_Time'].append(start_time)\n",
    "            data['End_Time'].append(end_time)\n",
    "            data['DiffTime_ms'].append(int(diff_time.group(1)) if diff_time else None)\n",
    "            data['ISO'].append(int(iso.group(1)) if iso else None)\n",
    "            data['Shutter'].append(shutter.group(1) if shutter else None)\n",
    "            data['Fnum'].append(int(fnum.group(1)) if fnum else None)\n",
    "            data['EV'].append(float(ev.group(1)) if ev else None)\n",
    "            data['CT'].append(int(ct.group(1)) if ct else None)\n",
    "            data['Color_Mode'].append(color_mode.group(1) if color_mode else None)\n",
    "            data['Focal_Length'].append(int(focal_len.group(1)) if focal_len else None)\n",
    "            data['Latitude'].append(float(latitude.group(1)) if latitude else None)\n",
    "            data['Longitude'].append(float(longitude.group(1)) if longitude else None)\n",
    "            data['Altitude'].append(float(altitude.group(1)) if altitude else None)\n",
    "            data['Image'].append(f'{general_path}images/{int(frame_count.group(1))-1}.jpg' if frame_count else None)\n",
    "\n",
    "    max_length = max(len(column) for column in data.values())\n",
    "    for key, column in data.items():\n",
    "        if len(column) < max_length:\n",
    "            column.extend([None] * (max_length - len(column)))\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df['FrameCnt'] = df['FrameCnt'].astype('Int64')\n",
    "    return df\n",
    "\n",
    "# Example usage: extract every 40th frame and save to 'images' folder\n",
    "video_file = '/home/oussama/Documents/EPFL/PDS_LUTS/Dataset/DJI_0763_output_trimmed.mp4'  # Replace with your video file path\n",
    "\n",
    "frame_interval=10\n",
    "\n",
    "extract_frames(video_file, 'images', frame_interval)\n",
    "\n",
    "# Define the path to the SRT file and the output CSV file\n",
    "srt_file = '/home/oussama/Documents/EPFL/PDS_LUTS/Dataset/DJI_0763.SRT'\n",
    "output_df_csv = '/home/oussama/Documents/EPFL/PDS_LUTS/Dataset/DJI_0763_data.csv'\n",
    "output_gps_csv = '/home/oussama/Documents/EPFL/PDS_LUTS/Dataset/DJI_0763_data_filtered.csv'\n",
    "\n",
    "# Parse the SRT file and save to CSV\n",
    "df = parse_srt_to_dataframe(srt_file)\n",
    "df.loc[:, 'FrameCnt'] = df['FrameCnt'] -1\n",
    "df.to_csv(output_df_csv, index=False)\n",
    "\n",
    "# Select only every 200th frame\n",
    "gps_df = df[df['FrameCnt'] % frame_interval == 1]\n",
    "\n",
    "gps_df.loc[:, 'FrameCnt'] = gps_df['FrameCnt'] -1\n",
    "\n",
    "# Save the filtered DataFrame to CSV\n",
    "gps_df.to_csv(output_gps_csv, index=False)\n",
    "print(f\"Filtered data saved to {output_gps_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 33 frames from the video.\n",
      "Selected frame indices (after checking blur): [0, 223, 413, 601, 791, 981, 1168, 1358, 1548, 1736, 1923, 2113, 2453, 2628, 2818, 3008, 3373, 3553, 3743, 3931, 4118, 4308, 4498, 4761, 4951, 5141, 5331, 5521, 6073, 6263, 6453, 6643, 6833]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def clear_folder(folder):\n",
    "    files = glob.glob(os.path.join(folder, '*'))\n",
    "    for f in files:\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except OSError as e:\n",
    "            print(f\"Error: {f} : {e.strerror}\")\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371e3  # Earth radius in meters\n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "    a = (np.sin(delta_phi / 2) ** 2\n",
    "         + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2) ** 2)\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def select_frames_by_distance(df, distance_threshold):\n",
    "    selected_frames = [0]  # Always start with frame 0\n",
    "    last_lat, last_lon = df.loc[0, 'Latitude'], df.loc[0, 'Longitude']\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        lat, lon = df.loc[i, 'Latitude'], df.loc[i, 'Longitude']\n",
    "        dist = haversine(last_lat, last_lon, lat, lon)\n",
    "        if dist >= distance_threshold:\n",
    "            selected_frames.append(i)\n",
    "            last_lat, last_lon = lat, lon\n",
    "    return selected_frames\n",
    "\n",
    "def is_not_blurry(frame, threshold=200.0):\n",
    "    \"\"\"\n",
    "    Determine if an image is blurry using the Laplacian variance method.\n",
    "    If the variance of the Laplacian is below the threshold, consider it blurry.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    variance = lap.var()\n",
    "    return variance > threshold\n",
    "\n",
    "def extract_frames_with_distance(video_path, output_folder, csv_file, distance_threshold=50, blur_threshold=200.0):\n",
    "    # Clear the output folder\n",
    "    clear_folder(output_folder)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Read the CSV and get the selected frames\n",
    "    df = pd.read_csv(csv_file)\n",
    "    selected_frames = select_frames_by_distance(df, distance_threshold)\n",
    "    \n",
    "    # Convert to a queue-like structure for processing\n",
    "    # We'll move through this list as we find suitable frames\n",
    "    target_indices = selected_frames.copy()\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}.\")\n",
    "        return\n",
    "\n",
    "    saved_frames = 0\n",
    "    final_selected_frames = []\n",
    "    \n",
    "    current_frame_index = 0\n",
    "    target_idx_pos = 0  # Position in the target_indices list\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            # No more frames\n",
    "            break\n",
    "\n",
    "        # If we've processed all target frames, stop\n",
    "        if target_idx_pos >= len(target_indices):\n",
    "            break\n",
    "\n",
    "        target_frame = target_indices[target_idx_pos]\n",
    "\n",
    "        if current_frame_index < target_frame:\n",
    "            # We haven't reached the target frame yet, just continue reading\n",
    "            current_frame_index += 1\n",
    "            continue\n",
    "\n",
    "        if current_frame_index == target_frame:\n",
    "            # Check if the frame at target_frame is blurry\n",
    "            if is_not_blurry(frame, blur_threshold):\n",
    "                # Not blurry, save it\n",
    "                cv2.imwrite(os.path.join(output_folder, f'{str(current_frame_index).zfill(4)}.jpg'), frame)\n",
    "                saved_frames += 1\n",
    "                final_selected_frames.append(current_frame_index)\n",
    "                target_idx_pos += 1\n",
    "            else:\n",
    "                # It's blurry, we need to keep reading subsequent frames until we find a non-blurry one\n",
    "                # Do not advance target_idx_pos yet, because we still need a suitable frame for this target\n",
    "                # Just continue the loop; the next iteration will read the next frame and check again\n",
    "                pass\n",
    "\n",
    "        else:\n",
    "            # current_frame_index > target_frame\n",
    "            # This means we already passed the target frame (likely because it was blurry)\n",
    "            # and we're checking subsequent frames to find a non-blurry one.\n",
    "            if is_not_blurry(frame, blur_threshold):\n",
    "                # Found a suitable frame after the target frame\n",
    "                cv2.imwrite(os.path.join(output_folder, f'{str(current_frame_index).zfill(4)}.jpg'), frame)\n",
    "                saved_frames += 1\n",
    "                final_selected_frames.append(current_frame_index)\n",
    "                target_idx_pos += 1\n",
    "            else:\n",
    "                # Still blurry, keep reading next frames\n",
    "                pass\n",
    "\n",
    "        current_frame_index += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted {saved_frames} frames from the video.\")\n",
    "    print(f\"Selected frame indices (after checking blur): {final_selected_frames}\")\n",
    "\n",
    "# Example usage:\n",
    "video_file = '/home/oussama/Documents/EPFL/PDS_LUTS/Dataset/DJI_0763.MOV'\n",
    "output_df_csv = '/home/oussama/Documents/EPFL/PDS_LUTS/Dataset/DJI_0763_data.csv'\n",
    "extract_frames_with_distance(video_file, 'images_distance', output_df_csv, distance_threshold=60, blur_threshold=200.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Haversine formula to calculate distance between two GPS coordinates in meters\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371e3  # Earth radius in meters\n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "    \n",
    "    a = np.sin(delta_phi / 2) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Get closest neighbors for each image based on GPS data\n",
    "def get_closest_neighbors(df, max_neighbors=5, max_distance=100):  # max_distance in meters\n",
    "    neighbors = {}\n",
    "    num_images = len(df)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        lat1, lon1 = df.iloc[i]['Latitude'], df.iloc[i]['Longitude']\n",
    "        distances = []\n",
    "        \n",
    "        for j in range(num_images):\n",
    "            if i != j:\n",
    "                lat2, lon2 = df.iloc[j]['Latitude'], df.iloc[j]['Longitude']\n",
    "                distance = haversine(lat1, lon1, lat2, lon2)\n",
    "                if distance <= max_distance:\n",
    "                    distances.append((distance, df.iloc[j]['FrameCnt']))\n",
    "        \n",
    "        # Sort by distance and select up to max_neighbors closest images\n",
    "        distances.sort()\n",
    "        neighbors[df.iloc[i]['FrameCnt']] = [j for _, j in distances[:max_neighbors]]\n",
    "    \n",
    "    return neighbors\n",
    "\n",
    "# Example usage\n",
    "# Assuming `gps_df` is a DataFrame with 'Latitude' and 'Longitude' columns for each image/frame\n",
    "neighbors = get_closest_neighbors(gps_df)\n",
    "\n",
    "gps_df['Neighbors'] = gps_df['FrameCnt'].map(neighbors)\n",
    "\n",
    "gps_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(neighbors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "video_path = \"Dataset/DJI_0763.MOV\"  # Path to the input video\n",
    "txt_folder_path = \"Dataset/DJI_0763_detection\"  # Path to the folder containing bounding box .txt files\n",
    "output_video_path = \"Dataset/bounding_boxes.mp4\"  # Path to save the output video with bounding boxes\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Define the codec and create a VideoWriter object to save the output video\n",
    "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "frame_idx = 0\n",
    "\n",
    "# Use tqdm for the progress bar\n",
    "with tqdm(total=total_frames, desc=\"Processing Video\", unit=\"frame\") as pbar:\n",
    "    # Loop through the video frames\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Exit when no more frames are available\n",
    "\n",
    "        # Corresponding .txt file for the current frame (assuming sequential filenames)\n",
    "        txt_file_path = os.path.join(txt_folder_path, f\"det_fr_{frame_idx:04d}.txt\")\n",
    "\n",
    "        if os.path.exists(txt_file_path):\n",
    "            # Read bounding boxes from the .txt file\n",
    "            with open(txt_file_path, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                # Split the line into values and parse them\n",
    "                values = line.strip().split(',')\n",
    "                # Extract the coordinates for the quadrilateral\n",
    "                x1, y1, x2, y2, x3, y3, x4, y4 = map(int, values[:8])\n",
    "                class_name = values[8]  # Object class\n",
    "                confidence = float(values[9])  # Confidence score\n",
    "\n",
    "                # Calculate the bounding rectangle (top-left and bottom-right coordinates)\n",
    "                x_min = min(x1, x2, x3, x4)\n",
    "                y_min = min(y1, y2, y3, y4)\n",
    "                x_max = max(x1, x2, x3, x4)\n",
    "                y_max = max(y1, y2, y3, y4)\n",
    "\n",
    "                # Draw the rectangle bounding box\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "                # Add the label (class and confidence score)\n",
    "                label = f\"{class_name} {confidence:.2f}\"\n",
    "                cv2.putText(frame, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Write the frame with bounding boxes to the output video\n",
    "        out.write(frame)\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "        # Increment the frame index\n",
    "        frame_idx += 1\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Video with bounding boxes saved at {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "from simple_lama_inpainting import SimpleLama\n",
    "\n",
    "# Step 1: Initialize SimpleLama\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "simple_lama = SimpleLama(device=device)\n",
    "\n",
    "# Step 2: Set Paths and Parameters\n",
    "general_path = '/home/oussama/Documents/EPFL/PDS_LUTS/'\n",
    "image_path = general_path + \"/images/250.jpg\"\n",
    "txt_file_path = general_path + \"Dataset/DJI_0763_detection/det_fr_0000.txt\"\n",
    "output_image_path = general_path + \"0_wo_boxes.jpg\"\n",
    "\n",
    "# Load the image and resize if needed (or keep original resolution for better quality)\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "dimensions = (3840, 2160)  # FHD example; adjust based on quality and memory\n",
    "fhd_image = image.resize(dimensions)\n",
    "mask = Image.new(\"L\", dimensions, 0)  \n",
    "\n",
    "# Scaling factors from 4K to FHD\n",
    "scaling_factor_x = dimensions[0] / 3840\n",
    "scaling_factor_y = dimensions[1] / 2160\n",
    "\n",
    "# Offset margin (extend box by these many pixels)\n",
    "offset = 10\n",
    "\n",
    "# Draw mask with bounding boxes + offset\n",
    "draw = ImageDraw.Draw(mask)\n",
    "with open(txt_file_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        values = list(map(int, line.strip().split(',')[:8]))\n",
    "        \n",
    "        # Original coordinates, scaled down\n",
    "        x1, y1 = int(values[0] * scaling_factor_x), int(values[1] * scaling_factor_y)\n",
    "        x2, y2 = int(values[2] * scaling_factor_x), int(values[3] * scaling_factor_y)\n",
    "        x3, y3 = int(values[4] * scaling_factor_x), int(values[5] * scaling_factor_y)\n",
    "        x4, y4 = int(values[6] * scaling_factor_x), int(values[7] * scaling_factor_y)\n",
    "\n",
    "        # Adjusted bounding box coordinates with offset\n",
    "        x_min = min(x1, x2, x3, x4) - offset\n",
    "        y_min = min(y1, y2, y3, y4) - offset\n",
    "        x_max = max(x1, x2, x3, x4) + offset\n",
    "        y_max = max(y1, y2, y3, y4) + offset\n",
    "        \n",
    "        # Draw the extended bounding box on the mask\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], fill=255)\n",
    "\n",
    "# mask.show()  # Optional: verify the mask visually\n",
    "\n",
    "# Perform inpainting with the modified mask\n",
    "result = simple_lama(fhd_image, mask)\n",
    "result.save(output_image_path)\n",
    "result.show()\n",
    "print(f\"Inpainted image saved at {output_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 33/33 [00:59<00:00,  1.80s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "from simple_lama_inpainting import SimpleLama\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "dimensions = (3840, 2160)\n",
    "\n",
    "# Initialize SimpleLama\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "simple_lama = SimpleLama(device=device)\n",
    "\n",
    "# Set Paths\n",
    "general_path = '/home/oussama/Documents/EPFL/PDS_LUTS/'\n",
    "input_folder = os.path.join(general_path, \"images_distance\")\n",
    "txt_folder = os.path.join(general_path, \"Dataset/DJI_0763_detection\")\n",
    "output_folder = os.path.join(general_path, f\"images_updated\")\n",
    "\n",
    "clear_folder(output_folder)\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Dimensions and scaling factors\n",
    "scaling_factor_x = dimensions[0] / 3840\n",
    "scaling_factor_y = dimensions[1] / 2160\n",
    "offset = 10  # Offset margin for bounding boxes\n",
    "\n",
    "# Regular expression patterns to extract frame numbers\n",
    "image_pattern = re.compile(r'(\\d+)\\.jpg$')\n",
    "txt_pattern = re.compile(r'det_fr_(\\d+)\\.txt$')\n",
    "\n",
    "# Create dictionaries for image files and txt files based on frame numbers\n",
    "image_files = {int(image_pattern.search(f).group(1)): f for f in os.listdir(input_folder) if image_pattern.search(f)}\n",
    "txt_files = {int(txt_pattern.search(f).group(1)): f for f in os.listdir(txt_folder) if txt_pattern.search(f)}\n",
    "\n",
    "# Sort frame numbers for sequential processing\n",
    "frame_numbers = sorted(set(image_files.keys()) & set(txt_files.keys()))\n",
    "\n",
    "# Loop through each frame with a progress bar\n",
    "for frame_number in tqdm(frame_numbers, desc=\"Processing images\"):\n",
    "    image_file = image_files[frame_number]\n",
    "    txt_file = txt_files[frame_number]\n",
    "\n",
    "    # Load the image\n",
    "    image_path = os.path.join(input_folder, image_file)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    fhd_image = image.resize(dimensions)\n",
    "    mask = Image.new(\"L\", dimensions, 0)\n",
    "\n",
    "    # Load the corresponding txt file\n",
    "    txt_file_path = os.path.join(txt_folder, txt_file)\n",
    "    \n",
    "    # Draw mask with bounding boxes + offset\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    with open(txt_file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            values = list(map(int, line.strip().split(',')[:8]))\n",
    "\n",
    "            # Scale and offset bounding box coordinates\n",
    "            x1, y1 = int(values[0] * scaling_factor_x), int(values[1] * scaling_factor_y)\n",
    "            x2, y2 = int(values[2] * scaling_factor_x), int(values[3] * scaling_factor_y)\n",
    "            x3, y3 = int(values[4] * scaling_factor_x), int(values[5] * scaling_factor_y)\n",
    "            x4, y4 = int(values[6] * scaling_factor_x), int(values[7] * scaling_factor_y)\n",
    "\n",
    "            x_min = min(x1, x2, x3, x4) - offset\n",
    "            y_min = min(y1, y2, y3, y4) - offset\n",
    "            x_max = max(x1, x2, x3, x4) + offset\n",
    "            y_max = max(y1, y2, y3, y4) + offset\n",
    "\n",
    "            draw.rectangle([x_min, y_min, x_max, y_max], fill=255)\n",
    "\n",
    "    # Perform inpainting\n",
    "    result = simple_lama(fhd_image, mask)\n",
    "\n",
    "    # Save the result\n",
    "    output_image_path = os.path.join(output_folder, image_file)\n",
    "    result.save(output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
